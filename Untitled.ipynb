{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import chess\n",
    "import chess.pgn\n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, Conv2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<LegalMoveGenerator at 0x17dea17c408 (Nh3, Nf3, Nc3, Na3, h3, g3, f3, e3, d3, c3, b3, a3, h4, g4, f4, e4, d4, c4, b4, a4)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "board = chess.Board()\n",
    "board.legal_moves "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"390\" version=\"1.1\" viewBox=\"0 0 390 390\" width=\"390\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs><g class=\"white pawn\" id=\"white-pawn\"><path d=\"M22 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38-1.95 1.12-3.28 3.21-3.28 5.62 0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#fff\" stroke=\"#000\" stroke-linecap=\"round\" stroke-width=\"1.5\" /></g><g class=\"white knight\" fill=\"none\" fill-rule=\"evenodd\" id=\"white-knight\" stroke=\"#000\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#ffffff; stroke:#000000;\" /><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#ffffff; stroke:#000000;\" /><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" style=\"fill:#000000; stroke:#000000;\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" /></g><g class=\"white bishop\" fill=\"none\" fill-rule=\"evenodd\" id=\"white-bishop\" stroke=\"#000\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"><g fill=\"#fff\" stroke-linecap=\"butt\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zM15 32c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" /></g><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke-linejoin=\"miter\" /></g><g class=\"white rook\" fill=\"#fff\" fill-rule=\"evenodd\" id=\"white-rook\" stroke=\"#000\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"><path d=\"M9 39h27v-3H9v3zM12 36v-4h21v4H12zM11 14V9h4v2h5V9h5v2h5V9h4v5\" stroke-linecap=\"butt\" /><path d=\"M34 14l-3 3H14l-3-3\" /><path d=\"M31 17v12.5H14V17\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M31 29.5l1.5 2.5h-20l1.5-2.5\" /><path d=\"M11 14h23\" fill=\"none\" stroke-linejoin=\"miter\" /></g><g class=\"white queen\" fill=\"#fff\" fill-rule=\"evenodd\" id=\"white-queen\" stroke=\"#000\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"><path d=\"M8 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM24.5 7.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM41 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM16 8.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM33 9a2 2 0 1 1-4 0 2 2 0 1 1 4 0z\" /><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2-12-7 11V11l-5.5 13.5-3-15-3 15-5.5-14V25L7 14l2 12zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\" /><path d=\"M11.5 30c3.5-1 18.5-1 22 0M12 33.5c6-1 15-1 21 0\" fill=\"none\" /></g><g class=\"white king\" fill=\"none\" fill-rule=\"evenodd\" id=\"white-king\" stroke=\"#000\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"><path d=\"M22.5 11.63V6M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#fff\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#fff\" /><path d=\"M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" /></g><g class=\"black pawn\" id=\"black-pawn\"><path d=\"M22 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38-1.95 1.12-3.28 3.21-3.28 5.62 0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" stroke=\"#000\" stroke-linecap=\"round\" stroke-width=\"1.5\" /></g><g class=\"black knight\" fill=\"none\" fill-rule=\"evenodd\" id=\"black-knight\" stroke=\"#000\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#ececec; stroke:#ececec;\" /><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" style=\"fill:#ececec; stroke:#ececec;\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" /><path d=\"M 24.55,10.4 L 24.1,11.85 L 24.6,12 C 27.75,13 30.25,14.49 32.5,18.75 C 34.75,23.01 35.75,29.06 35.25,39 L 35.2,39.5 L 37.45,39.5 L 37.5,39 C 38,28.94 36.62,22.15 34.25,17.66 C 31.88,13.17 28.46,11.02 25.06,10.5 L 24.55,10.4 z \" style=\"fill:#ececec; stroke:none;\" /></g><g class=\"black bishop\" fill=\"none\" fill-rule=\"evenodd\" id=\"black-bishop\" stroke=\"#000\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zm6-4c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" fill=\"#000\" stroke-linecap=\"butt\" /><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke=\"#fff\" stroke-linejoin=\"miter\" /></g><g class=\"black rook\" fill=\"#000\" fill-rule=\"evenodd\" id=\"black-rook\" stroke=\"#000\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"><path d=\"M9 39h27v-3H9v3zM12.5 32l1.5-2.5h17l1.5 2.5h-20zM12 36v-4h21v4H12z\" stroke-linecap=\"butt\" /><path d=\"M14 29.5v-13h17v13H14z\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M14 16.5L11 14h23l-3 2.5H14zM11 14V9h4v2h5V9h5v2h5V9h4v5H11z\" stroke-linecap=\"butt\" /><path d=\"M12 35.5h21M13 31.5h19M14 29.5h17M14 16.5h17M11 14h23\" fill=\"none\" stroke=\"#fff\" stroke-linejoin=\"miter\" stroke-width=\"1\" /></g><g class=\"black queen\" fill=\"#000\" fill-rule=\"evenodd\" id=\"black-queen\" stroke=\"#000\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"><g fill=\"#000\" stroke=\"none\"><circle cx=\"6\" cy=\"12\" r=\"2.75\" /><circle cx=\"14\" cy=\"9\" r=\"2.75\" /><circle cx=\"22.5\" cy=\"8\" r=\"2.75\" /><circle cx=\"31\" cy=\"9\" r=\"2.75\" /><circle cx=\"39\" cy=\"12\" r=\"2.75\" /></g><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2.5-12.5L31 25l-.3-14.1-5.2 13.6-3-14.5-3 14.5-5.2-13.6L14 25 6.5 13.5 9 26zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\" /><path d=\"M11 38.5a35 35 1 0 0 23 0\" fill=\"none\" stroke-linecap=\"butt\" /><path d=\"M11 29a35 35 1 0 1 23 0M12.5 31.5h20M11.5 34.5a35 35 1 0 0 22 0M10.5 37.5a35 35 1 0 0 24 0\" fill=\"none\" stroke=\"#fff\" /></g><g class=\"black king\" fill=\"none\" fill-rule=\"evenodd\" id=\"black-king\" stroke=\"#000\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.5\"><path d=\"M22.5 11.63V6\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#000\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#000\" /><path d=\"M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M32 29.5s8.5-4 6.03-9.65C34.15 14 25 18 22.5 24.5l.01 2.1-.01-2.1C20 18 9.906 14 6.997 19.85c-2.497 5.65 4.853 9 4.853 9M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" stroke=\"#fff\" /></g></defs><rect fill=\"#212121\" height=\"390\" width=\"390\" x=\"0\" y=\"0\" /><rect class=\"square dark a1\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"15\" y=\"330\" /><use transform=\"translate(15, 330)\" xlink:href=\"#white-rook\" /><rect class=\"square light b1\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"60\" y=\"330\" /><use transform=\"translate(60, 330)\" xlink:href=\"#white-knight\" /><rect class=\"square dark c1\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"105\" y=\"330\" /><use transform=\"translate(105, 330)\" xlink:href=\"#white-bishop\" /><rect class=\"square light d1\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"150\" y=\"330\" /><use transform=\"translate(150, 330)\" xlink:href=\"#white-queen\" /><rect class=\"square dark e1\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"195\" y=\"330\" /><use transform=\"translate(195, 330)\" xlink:href=\"#white-king\" /><rect class=\"square light f1\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"240\" y=\"330\" /><use transform=\"translate(240, 330)\" xlink:href=\"#white-bishop\" /><rect class=\"square dark g1\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"285\" y=\"330\" /><use transform=\"translate(285, 330)\" xlink:href=\"#white-knight\" /><rect class=\"square light h1\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"330\" y=\"330\" /><use transform=\"translate(330, 330)\" xlink:href=\"#white-rook\" /><rect class=\"square light a2\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"15\" y=\"285\" /><use transform=\"translate(15, 285)\" xlink:href=\"#white-pawn\" /><rect class=\"square dark b2\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"60\" y=\"285\" /><use transform=\"translate(60, 285)\" xlink:href=\"#white-pawn\" /><rect class=\"square light c2\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"105\" y=\"285\" /><use transform=\"translate(105, 285)\" xlink:href=\"#white-pawn\" /><rect class=\"square dark d2\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"150\" y=\"285\" /><use transform=\"translate(150, 285)\" xlink:href=\"#white-pawn\" /><rect class=\"square light e2\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"195\" y=\"285\" /><use transform=\"translate(195, 285)\" xlink:href=\"#white-pawn\" /><rect class=\"square dark f2\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"240\" y=\"285\" /><use transform=\"translate(240, 285)\" xlink:href=\"#white-pawn\" /><rect class=\"square light g2\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"285\" y=\"285\" /><use transform=\"translate(285, 285)\" xlink:href=\"#white-pawn\" /><rect class=\"square dark h2\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"330\" y=\"285\" /><use transform=\"translate(330, 285)\" xlink:href=\"#white-pawn\" /><rect class=\"square dark a3\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"15\" y=\"240\" /><rect class=\"square light b3\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"60\" y=\"240\" /><rect class=\"square dark c3\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"105\" y=\"240\" /><rect class=\"square light d3\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"150\" y=\"240\" /><rect class=\"square dark e3\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"195\" y=\"240\" /><rect class=\"square light f3\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"240\" y=\"240\" /><rect class=\"square dark g3\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"285\" y=\"240\" /><rect class=\"square light h3\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"330\" y=\"240\" /><rect class=\"square light a4\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"15\" y=\"195\" /><rect class=\"square dark b4\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"60\" y=\"195\" /><rect class=\"square light c4\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"105\" y=\"195\" /><rect class=\"square dark d4\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"150\" y=\"195\" /><rect class=\"square light e4\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"195\" y=\"195\" /><rect class=\"square dark f4\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"240\" y=\"195\" /><rect class=\"square light g4\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"285\" y=\"195\" /><rect class=\"square dark h4\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"330\" y=\"195\" /><rect class=\"square dark a5\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"15\" y=\"150\" /><rect class=\"square light b5\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"60\" y=\"150\" /><rect class=\"square dark c5\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"105\" y=\"150\" /><rect class=\"square light d5\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"150\" y=\"150\" /><rect class=\"square dark e5\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"195\" y=\"150\" /><rect class=\"square light f5\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"240\" y=\"150\" /><rect class=\"square dark g5\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"285\" y=\"150\" /><rect class=\"square light h5\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"330\" y=\"150\" /><rect class=\"square light a6\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"15\" y=\"105\" /><rect class=\"square dark b6\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"60\" y=\"105\" /><rect class=\"square light c6\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"105\" y=\"105\" /><rect class=\"square dark d6\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"150\" y=\"105\" /><rect class=\"square light e6\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"195\" y=\"105\" /><rect class=\"square dark f6\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"240\" y=\"105\" /><rect class=\"square light g6\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"285\" y=\"105\" /><rect class=\"square dark h6\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"330\" y=\"105\" /><rect class=\"square dark a7\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"15\" y=\"60\" /><use transform=\"translate(15, 60)\" xlink:href=\"#black-pawn\" /><rect class=\"square light b7\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"60\" y=\"60\" /><use transform=\"translate(60, 60)\" xlink:href=\"#black-pawn\" /><rect class=\"square dark c7\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"105\" y=\"60\" /><use transform=\"translate(105, 60)\" xlink:href=\"#black-pawn\" /><rect class=\"square light d7\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"150\" y=\"60\" /><use transform=\"translate(150, 60)\" xlink:href=\"#black-pawn\" /><rect class=\"square dark e7\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"195\" y=\"60\" /><use transform=\"translate(195, 60)\" xlink:href=\"#black-pawn\" /><rect class=\"square light f7\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"240\" y=\"60\" /><use transform=\"translate(240, 60)\" xlink:href=\"#black-pawn\" /><rect class=\"square dark g7\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"285\" y=\"60\" /><use transform=\"translate(285, 60)\" xlink:href=\"#black-pawn\" /><rect class=\"square light h7\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"330\" y=\"60\" /><use transform=\"translate(330, 60)\" xlink:href=\"#black-pawn\" /><rect class=\"square light a8\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"15\" y=\"15\" /><use transform=\"translate(15, 15)\" xlink:href=\"#black-rook\" /><rect class=\"square dark b8\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"60\" y=\"15\" /><use transform=\"translate(60, 15)\" xlink:href=\"#black-knight\" /><rect class=\"square light c8\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"105\" y=\"15\" /><use transform=\"translate(105, 15)\" xlink:href=\"#black-bishop\" /><rect class=\"square dark d8\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"150\" y=\"15\" /><use transform=\"translate(150, 15)\" xlink:href=\"#black-queen\" /><rect class=\"square light e8\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"195\" y=\"15\" /><use transform=\"translate(195, 15)\" xlink:href=\"#black-king\" /><rect class=\"square dark f8\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"240\" y=\"15\" /><use transform=\"translate(240, 15)\" xlink:href=\"#black-bishop\" /><rect class=\"square light g8\" fill=\"#ffce9e\" height=\"45\" stroke=\"none\" width=\"45\" x=\"285\" y=\"15\" /><use transform=\"translate(285, 15)\" xlink:href=\"#black-knight\" /><rect class=\"square dark h8\" fill=\"#d18b47\" height=\"45\" stroke=\"none\" width=\"45\" x=\"330\" y=\"15\" /><use transform=\"translate(330, 15)\" xlink:href=\"#black-rook\" /><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(20, 0) scale(0.75, 0.75)\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(20, 375) scale(0.75, 0.75)\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(65, 0) scale(0.75, 0.75)\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(65, 375) scale(0.75, 0.75)\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(110, 0) scale(0.75, 0.75)\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(110, 375) scale(0.75, 0.75)\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(155, 0) scale(0.75, 0.75)\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(155, 375) scale(0.75, 0.75)\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(200, 0) scale(0.75, 0.75)\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(200, 375) scale(0.75, 0.75)\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(245, 0) scale(0.75, 0.75)\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(245, 375) scale(0.75, 0.75)\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(290, 0) scale(0.75, 0.75)\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(290, 375) scale(0.75, 0.75)\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(335, 0) scale(0.75, 0.75)\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(335, 375) scale(0.75, 0.75)\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(0, 335) scale(0.75, 0.75)\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(375, 335) scale(0.75, 0.75)\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(0, 290) scale(0.75, 0.75)\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(375, 290) scale(0.75, 0.75)\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(0, 245) scale(0.75, 0.75)\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(375, 245) scale(0.75, 0.75)\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(0, 200) scale(0.75, 0.75)\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(375, 200) scale(0.75, 0.75)\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(0, 155) scale(0.75, 0.75)\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(375, 155) scale(0.75, 0.75)\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(0, 110) scale(0.75, 0.75)\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(375, 110) scale(0.75, 0.75)\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(0, 65) scale(0.75, 0.75)\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(375, 65) scale(0.75, 0.75)\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(0, 20) scale(0.75, 0.75)\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g><g fill=\"#e5e5e5\" stroke=\"#e5e5e5\" transform=\"translate(375, 20) scale(0.75, 0.75)\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g></svg>"
      ],
      "text/plain": [
       "Board('rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = []\n",
    "\n",
    "for x in range(0,64):\n",
    "    output.append(0)\n",
    "print(output)\n",
    "output[2] = 1\n",
    "print(output)\n",
    "len(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SringIntTester(nummer):\n",
    "    try: \n",
    "        int(nummer)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "    \n",
    "def Switcher(l, n): \n",
    "    for i in range(0, len(l), n):  \n",
    "        yield l[i:i + n] \n",
    "        \n",
    "        \n",
    "def GameMaker(game, piece_color):\n",
    "    gameRun = []\n",
    "    board = game.board()\n",
    "    for move in game.mainline_moves():\n",
    "        #print(board.fen())\n",
    "        if piece_color == board.turn:\n",
    "            gameRun.append([board.fen().split()[0], move.from_square, board.fullmove_number])\n",
    "        board.push(move)\n",
    "\n",
    "    for x in range(0, len(gameRun)):\n",
    "        gameRun[x].append(board.fullmove_number)\n",
    "\n",
    "    return gameRun\n",
    "\n",
    "def GameReadier(gameRun, transform):\n",
    "    gameRunReady = []\n",
    "    # gamerun = gameMaker(first_game, piece_color)\n",
    "    for move in gameRun:\n",
    "        temp = move[0].split(\"/\")\n",
    "        rowReady = []\n",
    "        for row in range(0,len(temp)):\n",
    "\n",
    "            letterBox = []\n",
    "            brokenList = list(str(temp[row]))\n",
    "\n",
    "            for letter in brokenList:\n",
    "                if SringIntTester(letter):  \n",
    "                    letterBox.extend(transform[letter]) \n",
    "                else: \n",
    "                    letterBox.append(transform[letter]) \n",
    "            #print(letterBox)\n",
    "            rowReady.append(letterBox)\n",
    "        gameRunReady.append((rowReady, move[1], move[2], move[3]))\n",
    "    #print(gameRunReady[0])\n",
    "    return gameRunReady\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "def inputMaker(filename, playername):\n",
    "\n",
    "    output = []\n",
    "    for x in range(0,64):\n",
    "        output.append(0)\n",
    "\n",
    "    transform = {\n",
    "        \"r\" : [1,0,0,0,0,0,0,0,0,0,0,0],\n",
    "        \"n\" : [0,1,0,0,0,0,0,0,0,0,0,0],\n",
    "        \"b\" : [0,0,1,0,0,0,0,0,0,0,0,0],\n",
    "        \"q\" : [0,0,0,1,0,0,0,0,0,0,0,0],\n",
    "        \"k\" : [0,0,0,0,1,0,0,0,0,0,0,0],\n",
    "        \"p\" : [0,0,0,0,0,1,0,0,0,0,0,0],\n",
    "        \"P\" : [0,0,0,0,0,0,1,0,0,0,0,0],\n",
    "        \"K\" : [0,0,0,0,0,0,0,1,0,0,0,0],\n",
    "        \"Q\" : [0,0,0,0,0,0,0,0,1,0,0,0],\n",
    "        \"B\" : [0,0,0,0,0,0,0,0,0,1,0,0],\n",
    "        \"N\" : [0,0,0,0,0,0,0,0,0,0,1,0],\n",
    "        \"R\" : [0,0,0,0,0,0,0,0,0,0,0,1],\n",
    "        \"1\" : [[0,0,0,0,0,0,0,0,0,0,0,0]],\n",
    "        \"2\" : [[0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0]],\n",
    "        \"3\" : [[0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0]],\n",
    "        \"4\" : [[0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0]],\n",
    "        \"5\" : [[0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0]],\n",
    "        \"6\" : [[0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0]],\n",
    "        \"7\" : [[0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0]],\n",
    "        \"8\" : [[0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0]]\n",
    "    }\n",
    "\n",
    "#     file = open(filename, mode='w') \n",
    "#     kopjes = ['board', 'answer', 'turn', 'totalTurns']\n",
    "#     writer = csv.DictWriter(file, delimiter=',', fieldnames = kopjes, lineterminator = '\\n')        \n",
    "\n",
    "    pgn = open(filename)\n",
    "    CompleteSet = []\n",
    "    while True:\n",
    "\n",
    "        eindeTest = chess.pgn.read_headers(pgn)\n",
    "        if eindeTest is None:\n",
    "            break\n",
    "\n",
    "        gameNow = chess.pgn.read_game(pgn)\n",
    "        piece_color = True\n",
    "        \n",
    "        \n",
    "        try:\n",
    "        \n",
    "        \n",
    "        \n",
    "            if re.search(playername, gameNow.headers[\"White\"]) != None:\n",
    "                piece_color = True\n",
    "            elif re.search(playername, gameNow.headers[\"Black\"]) != None:\n",
    "                piece_color = False\n",
    "        \n",
    "        \n",
    "        \n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        \n",
    "        \n",
    "        #print(first_game.headers)\n",
    "        gameImpr = GameMaker(gameNow, piece_color)\n",
    "        #print(gameImpr[1])\n",
    "        gameDone = GameReadier(gameImpr, transform)\n",
    "        #print(gameDone)\n",
    "        if piece_color == False:\n",
    "            for x in gameDone:\n",
    "                x[0].reverse()\n",
    "                for boards in x[0]:\n",
    "                    boards.reverse()    \n",
    "\n",
    "        #print(gameDone)\n",
    "\n",
    "        for singleBoardConfig in gameDone:\n",
    "            outputAnswer = output[:]\n",
    "            outputAnswer[singleBoardConfig[1]] = 1\n",
    "            if piece_color == False:\n",
    "                temp = list(Switcher(outputAnswer, 8))\n",
    "                temp.reverse()\n",
    "                temp2 = []\n",
    "                for x in temp:\n",
    "                    temp2.extend(x)\n",
    "                outputAnswer = temp2\n",
    "            #writer.writerow({'board' : singleBoardConfig[0], 'answer': outputAnswer, 'turn' : singleBoardConfig[2], 'totalTurns': singleBoardConfig[3]})\n",
    "\n",
    "            CompleteSet.append({'board' : singleBoardConfig[0], 'answer': outputAnswer, 'turn' : singleBoardConfig[2], 'totalTurns': singleBoardConfig[3]})\n",
    "    #         print(singleBoardConfig[0])\n",
    "    #         print(singleBoardConfig[1])\n",
    "    #         print(singleBoardConfig[2])\n",
    "\n",
    "    random.shuffle(CompleteSet)\n",
    "    \n",
    "    fullBoardArray = np.empty([len(CompleteSet), 8,8,12], dtype = np.int8)\n",
    "    fullAnswerArray = np.empty([len(CompleteSet), 64], dtype = np.int8)\n",
    "    fullTurnArray = np.empty([len(CompleteSet), 1], dtype = np.int8)\n",
    "    fullTotalturnArray = np.empty([len(CompleteSet), 1], dtype = np.int8)\n",
    "\n",
    "    for count, row in enumerate(CompleteSet):\n",
    "        #flatRowPre = [item for sublist in row['board'] for item in sublist]\n",
    "        #flatRow = [item for sublist in flatRowPre for item in sublist]\n",
    "\n",
    "        flatRow = row['board']\n",
    "\n",
    "        fullBoardArray[count] = np.array(flatRow)\n",
    "        fullAnswerArray[count] = np.array(row['answer'])\n",
    "        fullTurnArray[count] = np.array(row['turn'])\n",
    "        fullTotalturnArray[count] = np.array(row['totalTurns'])\n",
    "\n",
    "    \n",
    "    trainset = [fullBoardArray[:int(round((len(fullBoardArray)*0.90)))], fullAnswerArray[:int(round((len(fullBoardArray)*0.90)))], fullTurnArray[:int(round((len(fullBoardArray)*0.90)))], fullTotalturnArray[:int(round((len(fullBoardArray)*0.90)))]]\n",
    "    testset = [fullBoardArray[int(round((len(fullBoardArray)*0.90))):], fullAnswerArray[int(round((len(fullBoardArray)*0.90))):], fullTurnArray[int(round((len(fullBoardArray)*0.90))):], fullTotalturnArray[int(round((len(fullBoardArray)*0.90))):]]\n",
    "    \n",
    "    return [trainset, testset]\n",
    "#     file.close() \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Adams.pgn'\n",
    "playername = 'Adams'\n",
    "\n",
    "#CompleteSet = inputMaker('pgn/VachierLagrave.pgn', 'VachierLagrave')\n",
    "ultimateSet = []\n",
    "\n",
    "for filename in os.listdir('pgn'):\n",
    "    name = filename.split(\".\")\n",
    "    playerSet = inputMaker('pgn/'+filename, name[0])\n",
    "    ultimateSet.append(playerSet)\n",
    "\n",
    "#         with open(os.path.join('path/to/dir', filename)) as f:\n",
    "#             content = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 8, 8, 64)          3136      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 8, 8, 64)          16448     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8, 8, 256)         16640     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8, 8, 256)         65792     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                1048640   \n",
      "=================================================================\n",
      "Total params: 1,150,656\n",
      "Trainable params: 1,150,656\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(64, kernel_size=(2,2), padding='same', input_shape=(8, 8, 12), kernel_regularizer='l2', activation='relu'),\n",
    "    Conv2D(64, kernel_size=(2,2), padding='same', input_shape=(8, 8, 12), kernel_regularizer='l2', activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(64, activation = 'softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "5472/5472 - 21s - loss: 3.1884 - accuracy: 0.1815 - val_loss: 2.5859 - val_accuracy: 0.2612\n",
      "Epoch 2/30\n",
      "5472/5472 - 20s - loss: 2.4141 - accuracy: 0.2845 - val_loss: 2.3685 - val_accuracy: 0.2969\n",
      "Epoch 3/30\n",
      "5472/5472 - 21s - loss: 2.2279 - accuracy: 0.3166 - val_loss: 2.2919 - val_accuracy: 0.3021\n",
      "Epoch 4/30\n",
      "5472/5472 - 20s - loss: 2.1030 - accuracy: 0.3453 - val_loss: 2.2174 - val_accuracy: 0.3217\n",
      "Epoch 5/30\n",
      "5472/5472 - 20s - loss: 2.0097 - accuracy: 0.3671 - val_loss: 2.1688 - val_accuracy: 0.3337\n",
      "Epoch 6/30\n",
      "5472/5472 - 21s - loss: 1.9317 - accuracy: 0.3879 - val_loss: 2.1569 - val_accuracy: 0.3417\n",
      "Epoch 7/30\n",
      "5472/5472 - 21s - loss: 1.8632 - accuracy: 0.4069 - val_loss: 2.1132 - val_accuracy: 0.3401\n",
      "Epoch 8/30\n",
      "5472/5472 - 21s - loss: 1.8010 - accuracy: 0.4253 - val_loss: 2.1275 - val_accuracy: 0.3470\n",
      "Epoch 9/30\n",
      "5472/5472 - 21s - loss: 1.7469 - accuracy: 0.4422 - val_loss: 2.1123 - val_accuracy: 0.3521\n",
      "Epoch 10/30\n",
      "5472/5472 - 21s - loss: 1.6961 - accuracy: 0.4583 - val_loss: 2.1331 - val_accuracy: 0.3568\n",
      "Epoch 11/30\n",
      "5472/5472 - 22s - loss: 1.6493 - accuracy: 0.4744 - val_loss: 2.1353 - val_accuracy: 0.3565\n",
      "Epoch 12/30\n",
      "5472/5472 - 21s - loss: 1.6051 - accuracy: 0.4847 - val_loss: 2.1523 - val_accuracy: 0.3581\n",
      "Epoch 1/30\n",
      "6270/6270 - 25s - loss: 3.0741 - accuracy: 0.1886 - val_loss: 2.5631 - val_accuracy: 0.2466\n",
      "Epoch 2/30\n",
      "6270/6270 - 25s - loss: 2.3850 - accuracy: 0.2824 - val_loss: 2.3302 - val_accuracy: 0.2901\n",
      "Epoch 3/30\n",
      "6270/6270 - 26s - loss: 2.1965 - accuracy: 0.3192 - val_loss: 2.2252 - val_accuracy: 0.3074\n",
      "Epoch 4/30\n",
      "6270/6270 - 25s - loss: 2.0761 - accuracy: 0.3456 - val_loss: 2.1749 - val_accuracy: 0.3278\n",
      "Epoch 5/30\n",
      "6270/6270 - 26s - loss: 1.9883 - accuracy: 0.3687 - val_loss: 2.1282 - val_accuracy: 0.3309\n",
      "Epoch 6/30\n",
      "6270/6270 - 25s - loss: 1.9185 - accuracy: 0.3882 - val_loss: 2.1235 - val_accuracy: 0.3348\n",
      "Epoch 7/30\n",
      "6270/6270 - 26s - loss: 1.8601 - accuracy: 0.4011 - val_loss: 2.0903 - val_accuracy: 0.3437\n",
      "Epoch 8/30\n",
      "6270/6270 - 26s - loss: 1.8067 - accuracy: 0.4187 - val_loss: 2.0923 - val_accuracy: 0.3435\n",
      "Epoch 9/30\n",
      "6270/6270 - 26s - loss: 1.7572 - accuracy: 0.4308 - val_loss: 2.0698 - val_accuracy: 0.3519\n",
      "Epoch 10/30\n",
      "6270/6270 - 26s - loss: 1.7124 - accuracy: 0.4450 - val_loss: 2.0782 - val_accuracy: 0.3530\n",
      "Epoch 11/30\n",
      "6270/6270 - 26s - loss: 1.6720 - accuracy: 0.4591 - val_loss: 2.0646 - val_accuracy: 0.3565\n",
      "Epoch 12/30\n",
      "6270/6270 - 26s - loss: 1.6342 - accuracy: 0.4690 - val_loss: 2.0662 - val_accuracy: 0.3629\n",
      "Epoch 13/30\n",
      "6270/6270 - 27s - loss: 1.5962 - accuracy: 0.4812 - val_loss: 2.1103 - val_accuracy: 0.3491\n",
      "Epoch 14/30\n",
      "6270/6270 - 26s - loss: 1.5620 - accuracy: 0.4943 - val_loss: 2.0662 - val_accuracy: 0.3648\n",
      "Epoch 1/30\n",
      "5980/5980 - 20s - loss: 3.1399 - accuracy: 0.1802 - val_loss: 2.5914 - val_accuracy: 0.2476\n",
      "Epoch 2/30\n",
      "5980/5980 - 19s - loss: 2.4473 - accuracy: 0.2648 - val_loss: 2.3849 - val_accuracy: 0.2723\n",
      "Epoch 3/30\n",
      "5980/5980 - 21s - loss: 2.2684 - accuracy: 0.2957 - val_loss: 2.2815 - val_accuracy: 0.2930\n",
      "Epoch 4/30\n",
      "5980/5980 - 20s - loss: 2.1393 - accuracy: 0.3241 - val_loss: 2.2275 - val_accuracy: 0.3039\n",
      "Epoch 5/30\n",
      "5980/5980 - 20s - loss: 2.0403 - accuracy: 0.3513 - val_loss: 2.1895 - val_accuracy: 0.3119\n",
      "Epoch 6/30\n",
      "5980/5980 - 19s - loss: 1.9596 - accuracy: 0.3709 - val_loss: 2.1497 - val_accuracy: 0.3264\n",
      "Epoch 7/30\n",
      "5980/5980 - 19s - loss: 1.8949 - accuracy: 0.3905 - val_loss: 2.1290 - val_accuracy: 0.3390\n",
      "Epoch 8/30\n",
      "5980/5980 - 20s - loss: 1.8374 - accuracy: 0.4089 - val_loss: 2.0840 - val_accuracy: 0.3465\n",
      "Epoch 9/30\n",
      "5980/5980 - 20s - loss: 1.7890 - accuracy: 0.4225 - val_loss: 2.0929 - val_accuracy: 0.3467\n",
      "Epoch 10/30\n",
      "5980/5980 - 19s - loss: 1.7453 - accuracy: 0.4346 - val_loss: 2.0905 - val_accuracy: 0.3481\n",
      "Epoch 11/30\n",
      "5980/5980 - 19s - loss: 1.7022 - accuracy: 0.4505 - val_loss: 2.0983 - val_accuracy: 0.3521\n",
      "Epoch 1/30\n",
      "4910/4910 - 21s - loss: 3.2885 - accuracy: 0.1594 - val_loss: 2.7189 - val_accuracy: 0.2236\n",
      "Epoch 2/30\n",
      "4910/4910 - 21s - loss: 2.5094 - accuracy: 0.2597 - val_loss: 2.4866 - val_accuracy: 0.2595\n",
      "Epoch 3/30\n",
      "4910/4910 - 20s - loss: 2.3368 - accuracy: 0.2905 - val_loss: 2.3934 - val_accuracy: 0.2732\n",
      "Epoch 4/30\n",
      "4910/4910 - 19s - loss: 2.2163 - accuracy: 0.3183 - val_loss: 2.3252 - val_accuracy: 0.2952\n",
      "Epoch 5/30\n",
      "4910/4910 - 19s - loss: 2.1218 - accuracy: 0.3405 - val_loss: 2.2721 - val_accuracy: 0.3101\n",
      "Epoch 6/30\n",
      "4910/4910 - 19s - loss: 2.0417 - accuracy: 0.3579 - val_loss: 2.2388 - val_accuracy: 0.3154\n",
      "Epoch 7/30\n",
      "4910/4910 - 20s - loss: 1.9713 - accuracy: 0.3765 - val_loss: 2.2365 - val_accuracy: 0.3158\n",
      "Epoch 8/30\n",
      "4910/4910 - 19s - loss: 1.9108 - accuracy: 0.3922 - val_loss: 2.2004 - val_accuracy: 0.3247\n",
      "Epoch 9/30\n",
      "4910/4910 - 19s - loss: 1.8568 - accuracy: 0.4062 - val_loss: 2.1923 - val_accuracy: 0.3349\n",
      "Epoch 10/30\n",
      "4910/4910 - 19s - loss: 1.8025 - accuracy: 0.4263 - val_loss: 2.1936 - val_accuracy: 0.3340\n",
      "Epoch 11/30\n",
      "4910/4910 - 19s - loss: 1.7590 - accuracy: 0.4349 - val_loss: 2.2085 - val_accuracy: 0.3308\n",
      "Epoch 12/30\n",
      "4910/4910 - 19s - loss: 1.7135 - accuracy: 0.4483 - val_loss: 2.2002 - val_accuracy: 0.3363\n",
      "Epoch 1/30\n",
      "5386/5386 - 22s - loss: 3.1998 - accuracy: 0.1760 - val_loss: 2.6182 - val_accuracy: 0.2512\n",
      "Epoch 2/30\n",
      "5386/5386 - 21s - loss: 2.4390 - accuracy: 0.2766 - val_loss: 2.3722 - val_accuracy: 0.2801\n",
      "Epoch 3/30\n",
      "5386/5386 - 21s - loss: 2.2320 - accuracy: 0.3094 - val_loss: 2.2596 - val_accuracy: 0.3081\n",
      "Epoch 4/30\n",
      "5386/5386 - 21s - loss: 2.0995 - accuracy: 0.3406 - val_loss: 2.1971 - val_accuracy: 0.3194\n",
      "Epoch 5/30\n",
      "5386/5386 - 22s - loss: 2.0027 - accuracy: 0.3638 - val_loss: 2.1661 - val_accuracy: 0.3291\n",
      "Epoch 6/30\n",
      "5386/5386 - 22s - loss: 1.9232 - accuracy: 0.3842 - val_loss: 2.1501 - val_accuracy: 0.3358\n",
      "Epoch 7/30\n",
      "5386/5386 - 21s - loss: 1.8618 - accuracy: 0.4044 - val_loss: 2.1463 - val_accuracy: 0.3389\n",
      "Epoch 8/30\n",
      "5386/5386 - 22s - loss: 1.8053 - accuracy: 0.4206 - val_loss: 2.1484 - val_accuracy: 0.3372\n",
      "Epoch 9/30\n",
      "5386/5386 - 22s - loss: 1.7558 - accuracy: 0.4371 - val_loss: 2.1450 - val_accuracy: 0.3405\n",
      "Epoch 10/30\n",
      "5386/5386 - 21s - loss: 1.7088 - accuracy: 0.4527 - val_loss: 2.1184 - val_accuracy: 0.3454\n",
      "Epoch 11/30\n",
      "5386/5386 - 22s - loss: 1.6650 - accuracy: 0.4662 - val_loss: 2.1415 - val_accuracy: 0.3480\n",
      "Epoch 12/30\n",
      "5386/5386 - 22s - loss: 1.6278 - accuracy: 0.4773 - val_loss: 2.1430 - val_accuracy: 0.3506\n",
      "Epoch 13/30\n",
      "5386/5386 - 21s - loss: 1.5873 - accuracy: 0.4893 - val_loss: 2.1641 - val_accuracy: 0.3515\n",
      "Epoch 1/30\n",
      "6219/6219 - 24s - loss: 3.1795 - accuracy: 0.1681 - val_loss: 2.5925 - val_accuracy: 0.2376\n",
      "Epoch 2/30\n",
      "6219/6219 - 24s - loss: 2.4516 - accuracy: 0.2626 - val_loss: 2.3957 - val_accuracy: 0.2720\n",
      "Epoch 3/30\n",
      "6219/6219 - 26s - loss: 2.2665 - accuracy: 0.2959 - val_loss: 2.2969 - val_accuracy: 0.2913\n",
      "Epoch 4/30\n",
      "6219/6219 - 26s - loss: 2.1421 - accuracy: 0.3216 - val_loss: 2.2271 - val_accuracy: 0.3114\n",
      "Epoch 5/30\n",
      "6219/6219 - 25s - loss: 2.0508 - accuracy: 0.3458 - val_loss: 2.1741 - val_accuracy: 0.3232\n",
      "Epoch 6/30\n",
      "6219/6219 - 26s - loss: 1.9782 - accuracy: 0.3646 - val_loss: 2.1549 - val_accuracy: 0.3223\n",
      "Epoch 7/30\n",
      "6219/6219 - 24s - loss: 1.9166 - accuracy: 0.3809 - val_loss: 2.1351 - val_accuracy: 0.3298\n",
      "Epoch 8/30\n",
      "6219/6219 - 24s - loss: 1.8648 - accuracy: 0.3963 - val_loss: 2.1362 - val_accuracy: 0.3334\n",
      "Epoch 9/30\n",
      "6219/6219 - 25s - loss: 1.8179 - accuracy: 0.4133 - val_loss: 2.1290 - val_accuracy: 0.3365\n",
      "Epoch 10/30\n",
      "6219/6219 - 25s - loss: 1.7742 - accuracy: 0.4228 - val_loss: 2.1212 - val_accuracy: 0.3326\n",
      "Epoch 11/30\n",
      "6219/6219 - 26s - loss: 1.7358 - accuracy: 0.4330 - val_loss: 2.1182 - val_accuracy: 0.3396\n",
      "Epoch 12/30\n",
      "6219/6219 - 24s - loss: 1.6967 - accuracy: 0.4469 - val_loss: 2.1253 - val_accuracy: 0.3366\n",
      "Epoch 13/30\n",
      "6219/6219 - 25s - loss: 1.6609 - accuracy: 0.4599 - val_loss: 2.1350 - val_accuracy: 0.3356\n",
      "Epoch 14/30\n",
      "6219/6219 - 24s - loss: 1.6290 - accuracy: 0.4680 - val_loss: 2.1480 - val_accuracy: 0.3366\n",
      "Epoch 1/30\n",
      "5777/5777 - 24s - loss: 3.1361 - accuracy: 0.1947 - val_loss: 2.6156 - val_accuracy: 0.2547\n",
      "Epoch 2/30\n",
      "5777/5777 - 22s - loss: 2.3971 - accuracy: 0.2891 - val_loss: 2.3625 - val_accuracy: 0.2928\n",
      "Epoch 3/30\n",
      "5777/5777 - 23s - loss: 2.1976 - accuracy: 0.3290 - val_loss: 2.2558 - val_accuracy: 0.3133\n",
      "Epoch 4/30\n",
      "5777/5777 - 22s - loss: 2.0651 - accuracy: 0.3573 - val_loss: 2.2097 - val_accuracy: 0.3312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "5777/5777 - 23s - loss: 1.9635 - accuracy: 0.3824 - val_loss: 2.1443 - val_accuracy: 0.3434\n",
      "Epoch 6/30\n",
      "5777/5777 - 22s - loss: 1.8848 - accuracy: 0.4027 - val_loss: 2.1414 - val_accuracy: 0.3441\n",
      "Epoch 7/30\n",
      "5777/5777 - 22s - loss: 1.8181 - accuracy: 0.4211 - val_loss: 2.1036 - val_accuracy: 0.3613\n",
      "Epoch 8/30\n",
      "5777/5777 - 23s - loss: 1.7618 - accuracy: 0.4377 - val_loss: 2.1001 - val_accuracy: 0.3575\n",
      "Epoch 9/30\n",
      "5777/5777 - 23s - loss: 1.7108 - accuracy: 0.4549 - val_loss: 2.0804 - val_accuracy: 0.3623\n",
      "Epoch 10/30\n",
      "5777/5777 - 23s - loss: 1.6689 - accuracy: 0.4676 - val_loss: 2.0576 - val_accuracy: 0.3686\n",
      "Epoch 11/30\n",
      "5777/5777 - 22s - loss: 1.6264 - accuracy: 0.4783 - val_loss: 2.1149 - val_accuracy: 0.3641\n",
      "Epoch 12/30\n",
      "5777/5777 - 23s - loss: 1.5897 - accuracy: 0.4905 - val_loss: 2.1262 - val_accuracy: 0.3636\n",
      "Epoch 13/30\n",
      "5777/5777 - 22s - loss: 1.5522 - accuracy: 0.5043 - val_loss: 2.0947 - val_accuracy: 0.3717\n",
      "Epoch 1/30\n",
      "7200/7200 - 28s - loss: 3.0626 - accuracy: 0.1815 - val_loss: 2.5739 - val_accuracy: 0.2383\n",
      "Epoch 2/30\n",
      "7200/7200 - 27s - loss: 2.4126 - accuracy: 0.2620 - val_loss: 2.3660 - val_accuracy: 0.2710\n",
      "Epoch 3/30\n",
      "7200/7200 - 27s - loss: 2.2295 - accuracy: 0.2980 - val_loss: 2.2509 - val_accuracy: 0.2991\n",
      "Epoch 4/30\n",
      "7200/7200 - 27s - loss: 2.1103 - accuracy: 0.3238 - val_loss: 2.1764 - val_accuracy: 0.3071\n",
      "Epoch 5/30\n",
      "7200/7200 - 27s - loss: 2.0208 - accuracy: 0.3482 - val_loss: 2.1365 - val_accuracy: 0.3260\n",
      "Epoch 6/30\n",
      "7200/7200 - 27s - loss: 1.9445 - accuracy: 0.3696 - val_loss: 2.1095 - val_accuracy: 0.3283\n",
      "Epoch 7/30\n",
      "7200/7200 - 27s - loss: 1.8816 - accuracy: 0.3875 - val_loss: 2.0953 - val_accuracy: 0.3350\n",
      "Epoch 8/30\n",
      "7200/7200 - 28s - loss: 1.8275 - accuracy: 0.4030 - val_loss: 2.0697 - val_accuracy: 0.3389\n",
      "Epoch 9/30\n",
      "7200/7200 - 28s - loss: 1.7752 - accuracy: 0.4200 - val_loss: 2.0767 - val_accuracy: 0.3414\n",
      "Epoch 10/30\n",
      "7200/7200 - 28s - loss: 1.7300 - accuracy: 0.4333 - val_loss: 2.0701 - val_accuracy: 0.3459\n",
      "Epoch 11/30\n",
      "7200/7200 - 28s - loss: 1.6869 - accuracy: 0.4462 - val_loss: 2.0824 - val_accuracy: 0.3487\n",
      "Epoch 1/30\n",
      "5751/5751 - 23s - loss: 3.1439 - accuracy: 0.1802 - val_loss: 2.6399 - val_accuracy: 0.2348\n",
      "Epoch 2/30\n",
      "5751/5751 - 22s - loss: 2.4496 - accuracy: 0.2721 - val_loss: 2.4553 - val_accuracy: 0.2699\n",
      "Epoch 3/30\n",
      "5751/5751 - 22s - loss: 2.2881 - accuracy: 0.3030 - val_loss: 2.3405 - val_accuracy: 0.2968\n",
      "Epoch 4/30\n",
      "5751/5751 - 22s - loss: 2.1740 - accuracy: 0.3266 - val_loss: 2.2810 - val_accuracy: 0.3024\n",
      "Epoch 5/30\n",
      "5751/5751 - 22s - loss: 2.0827 - accuracy: 0.3465 - val_loss: 2.2268 - val_accuracy: 0.3160\n",
      "Epoch 6/30\n",
      "5751/5751 - 22s - loss: 2.0066 - accuracy: 0.3677 - val_loss: 2.1816 - val_accuracy: 0.3272\n",
      "Epoch 7/30\n",
      "5751/5751 - 22s - loss: 1.9434 - accuracy: 0.3838 - val_loss: 2.1603 - val_accuracy: 0.3305\n",
      "Epoch 8/30\n",
      "5751/5751 - 23s - loss: 1.8827 - accuracy: 0.3987 - val_loss: 2.1493 - val_accuracy: 0.3320\n",
      "Epoch 9/30\n",
      "5751/5751 - 22s - loss: 1.8307 - accuracy: 0.4153 - val_loss: 2.1589 - val_accuracy: 0.3260\n",
      "Epoch 10/30\n",
      "5751/5751 - 22s - loss: 1.7827 - accuracy: 0.4284 - val_loss: 2.1262 - val_accuracy: 0.3384\n",
      "Epoch 11/30\n",
      "5751/5751 - 23s - loss: 1.7394 - accuracy: 0.4405 - val_loss: 2.1499 - val_accuracy: 0.3400\n",
      "Epoch 12/30\n",
      "5751/5751 - 23s - loss: 1.6978 - accuracy: 0.4551 - val_loss: 2.1342 - val_accuracy: 0.3440\n",
      "Epoch 13/30\n",
      "5751/5751 - 23s - loss: 1.6571 - accuracy: 0.4670 - val_loss: 2.1677 - val_accuracy: 0.3469\n",
      "Epoch 1/30\n",
      "7635/7635 - 32s - loss: 2.7105 - accuracy: 0.2419 - val_loss: 2.3395 - val_accuracy: 0.2894\n",
      "Epoch 2/30\n",
      "7635/7635 - 31s - loss: 2.2334 - accuracy: 0.3132 - val_loss: 2.1991 - val_accuracy: 0.3172\n",
      "Epoch 3/30\n",
      "7635/7635 - 32s - loss: 2.1071 - accuracy: 0.3413 - val_loss: 2.1514 - val_accuracy: 0.3144\n",
      "Epoch 4/30\n",
      "7635/7635 - 31s - loss: 2.0199 - accuracy: 0.3589 - val_loss: 2.0804 - val_accuracy: 0.3364\n",
      "Epoch 5/30\n",
      "7635/7635 - 31s - loss: 1.9487 - accuracy: 0.3758 - val_loss: 2.0638 - val_accuracy: 0.3386\n",
      "Epoch 6/30\n",
      "7635/7635 - 32s - loss: 1.8921 - accuracy: 0.3883 - val_loss: 2.0424 - val_accuracy: 0.3397\n",
      "Epoch 7/30\n",
      "7635/7635 - 31s - loss: 1.8439 - accuracy: 0.4012 - val_loss: 2.0290 - val_accuracy: 0.3491\n",
      "Epoch 8/30\n",
      "7635/7635 - 34s - loss: 1.8040 - accuracy: 0.4094 - val_loss: 2.0338 - val_accuracy: 0.3493\n",
      "Epoch 9/30\n",
      "7635/7635 - 34s - loss: 1.7640 - accuracy: 0.4212 - val_loss: 2.0211 - val_accuracy: 0.3457\n",
      "Epoch 10/30\n",
      "7635/7635 - 35s - loss: 1.7301 - accuracy: 0.4321 - val_loss: 2.0392 - val_accuracy: 0.3496\n",
      "Epoch 11/30\n",
      "7635/7635 - 34s - loss: 1.6982 - accuracy: 0.4395 - val_loss: 2.0392 - val_accuracy: 0.3503\n",
      "Epoch 12/30\n",
      "7635/7635 - 34s - loss: 1.6668 - accuracy: 0.4493 - val_loss: 2.0119 - val_accuracy: 0.3494\n",
      "Epoch 13/30\n",
      "7635/7635 - 35s - loss: 1.6370 - accuracy: 0.4611 - val_loss: 2.0322 - val_accuracy: 0.3581\n",
      "Epoch 14/30\n",
      "7635/7635 - 34s - loss: 1.6068 - accuracy: 0.4698 - val_loss: 2.0355 - val_accuracy: 0.3571\n",
      "Epoch 15/30\n",
      "7635/7635 - 34s - loss: 1.5785 - accuracy: 0.4802 - val_loss: 2.0499 - val_accuracy: 0.3590\n",
      "Epoch 1/30\n",
      "5164/5164 - 24s - loss: 3.2239 - accuracy: 0.1670 - val_loss: 2.6439 - val_accuracy: 0.2298\n",
      "Epoch 2/30\n",
      "5164/5164 - 22s - loss: 2.4966 - accuracy: 0.2582 - val_loss: 2.4365 - val_accuracy: 0.2714\n",
      "Epoch 3/30\n",
      "5164/5164 - 21s - loss: 2.3175 - accuracy: 0.2883 - val_loss: 2.3439 - val_accuracy: 0.2939\n",
      "Epoch 4/30\n",
      "5164/5164 - 22s - loss: 2.1966 - accuracy: 0.3146 - val_loss: 2.2803 - val_accuracy: 0.3004\n",
      "Epoch 5/30\n",
      "5164/5164 - 23s - loss: 2.1052 - accuracy: 0.3370 - val_loss: 2.2296 - val_accuracy: 0.3147\n",
      "Epoch 6/30\n",
      "5164/5164 - 21s - loss: 2.0243 - accuracy: 0.3600 - val_loss: 2.2060 - val_accuracy: 0.3139\n",
      "Epoch 7/30\n",
      "5164/5164 - 21s - loss: 1.9596 - accuracy: 0.3762 - val_loss: 2.1682 - val_accuracy: 0.3277\n",
      "Epoch 8/30\n",
      "5164/5164 - 21s - loss: 1.9021 - accuracy: 0.3894 - val_loss: 2.1638 - val_accuracy: 0.3226\n",
      "Epoch 9/30\n",
      "5164/5164 - 22s - loss: 1.8513 - accuracy: 0.4048 - val_loss: 2.1530 - val_accuracy: 0.3356\n",
      "Epoch 10/30\n",
      "5164/5164 - 22s - loss: 1.8046 - accuracy: 0.4192 - val_loss: 2.1560 - val_accuracy: 0.3303\n",
      "Epoch 11/30\n",
      "5164/5164 - 21s - loss: 1.7616 - accuracy: 0.4332 - val_loss: 2.1484 - val_accuracy: 0.3378\n",
      "Epoch 12/30\n",
      "5164/5164 - 21s - loss: 1.7230 - accuracy: 0.4432 - val_loss: 2.1490 - val_accuracy: 0.3403\n",
      "Epoch 13/30\n",
      "5164/5164 - 21s - loss: 1.6832 - accuracy: 0.4557 - val_loss: 2.1458 - val_accuracy: 0.3361\n",
      "Epoch 14/30\n",
      "5164/5164 - 21s - loss: 1.6471 - accuracy: 0.4681 - val_loss: 2.1821 - val_accuracy: 0.3426\n",
      "Epoch 15/30\n",
      "5164/5164 - 21s - loss: 1.6141 - accuracy: 0.4770 - val_loss: 2.1691 - val_accuracy: 0.3435\n",
      "Epoch 16/30\n",
      "5164/5164 - 21s - loss: 1.5830 - accuracy: 0.4862 - val_loss: 2.1848 - val_accuracy: 0.3356\n",
      "Epoch 1/30\n",
      "5469/5469 - 23s - loss: 3.1803 - accuracy: 0.1741 - val_loss: 2.6541 - val_accuracy: 0.2426\n",
      "Epoch 2/30\n",
      "5469/5469 - 22s - loss: 2.4875 - accuracy: 0.2591 - val_loss: 2.4679 - val_accuracy: 0.2658\n",
      "Epoch 3/30\n",
      "5469/5469 - 22s - loss: 2.3198 - accuracy: 0.2911 - val_loss: 2.3810 - val_accuracy: 0.2797\n",
      "Epoch 4/30\n",
      "5469/5469 - 22s - loss: 2.2029 - accuracy: 0.3171 - val_loss: 2.3106 - val_accuracy: 0.2886\n",
      "Epoch 5/30\n",
      "5469/5469 - 22s - loss: 2.1108 - accuracy: 0.3386 - val_loss: 2.2604 - val_accuracy: 0.3090\n",
      "Epoch 6/30\n",
      "5469/5469 - 22s - loss: 2.0343 - accuracy: 0.3601 - val_loss: 2.2396 - val_accuracy: 0.3116\n",
      "Epoch 7/30\n",
      "5469/5469 - 22s - loss: 1.9658 - accuracy: 0.3766 - val_loss: 2.2063 - val_accuracy: 0.3222\n",
      "Epoch 8/30\n",
      "5469/5469 - 22s - loss: 1.9069 - accuracy: 0.3931 - val_loss: 2.1984 - val_accuracy: 0.3217\n",
      "Epoch 9/30\n",
      "5469/5469 - 21s - loss: 1.8524 - accuracy: 0.4073 - val_loss: 2.1841 - val_accuracy: 0.3340\n",
      "Epoch 10/30\n",
      "5469/5469 - 22s - loss: 1.8039 - accuracy: 0.4210 - val_loss: 2.1983 - val_accuracy: 0.3273\n",
      "Epoch 11/30\n",
      "5469/5469 - 22s - loss: 1.7565 - accuracy: 0.4349 - val_loss: 2.1967 - val_accuracy: 0.3304\n",
      "Epoch 12/30\n",
      "5469/5469 - 22s - loss: 1.7181 - accuracy: 0.4491 - val_loss: 2.1792 - val_accuracy: 0.3333\n",
      "Epoch 13/30\n",
      "5469/5469 - 22s - loss: 1.6765 - accuracy: 0.4611 - val_loss: 2.2384 - val_accuracy: 0.3387\n",
      "Epoch 14/30\n",
      "5469/5469 - 24s - loss: 1.6401 - accuracy: 0.4723 - val_loss: 2.2063 - val_accuracy: 0.3405\n",
      "Epoch 15/30\n",
      "5469/5469 - 23s - loss: 1.6015 - accuracy: 0.4871 - val_loss: 2.2432 - val_accuracy: 0.3438\n",
      "Epoch 1/30\n",
      "7579/7579 - 31s - loss: 3.0893 - accuracy: 0.1765 - val_loss: 2.5903 - val_accuracy: 0.2349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "7579/7579 - 30s - loss: 2.4370 - accuracy: 0.2622 - val_loss: 2.3900 - val_accuracy: 0.2679\n",
      "Epoch 3/30\n",
      "7579/7579 - 30s - loss: 2.2621 - accuracy: 0.2929 - val_loss: 2.3070 - val_accuracy: 0.2777\n",
      "Epoch 4/30\n",
      "7579/7579 - 30s - loss: 2.1400 - accuracy: 0.3210 - val_loss: 2.2223 - val_accuracy: 0.2964\n",
      "Epoch 5/30\n",
      "7579/7579 - 30s - loss: 2.0495 - accuracy: 0.3417 - val_loss: 2.1734 - val_accuracy: 0.3147\n",
      "Epoch 6/30\n",
      "7579/7579 - 30s - loss: 1.9779 - accuracy: 0.3631 - val_loss: 2.1397 - val_accuracy: 0.3208\n",
      "Epoch 7/30\n",
      "7579/7579 - 30s - loss: 1.9160 - accuracy: 0.3822 - val_loss: 2.1151 - val_accuracy: 0.3216\n",
      "Epoch 8/30\n",
      "7579/7579 - 30s - loss: 1.8639 - accuracy: 0.3938 - val_loss: 2.1059 - val_accuracy: 0.3295\n",
      "Epoch 9/30\n",
      "7579/7579 - 31s - loss: 1.8178 - accuracy: 0.4078 - val_loss: 2.1035 - val_accuracy: 0.3304\n",
      "Epoch 10/30\n",
      "7579/7579 - 31s - loss: 1.7756 - accuracy: 0.4230 - val_loss: 2.0925 - val_accuracy: 0.3329\n",
      "Epoch 11/30\n",
      "7579/7579 - 32s - loss: 1.7385 - accuracy: 0.4339 - val_loss: 2.0970 - val_accuracy: 0.3304\n",
      "Epoch 12/30\n",
      "7579/7579 - 31s - loss: 1.7025 - accuracy: 0.4444 - val_loss: 2.0922 - val_accuracy: 0.3419\n",
      "Epoch 13/30\n",
      "7579/7579 - 31s - loss: 1.6692 - accuracy: 0.4561 - val_loss: 2.0877 - val_accuracy: 0.3443\n",
      "Epoch 14/30\n",
      "7579/7579 - 32s - loss: 1.6382 - accuracy: 0.4649 - val_loss: 2.0974 - val_accuracy: 0.3500\n",
      "Epoch 15/30\n",
      "7579/7579 - 30s - loss: 1.6078 - accuracy: 0.4748 - val_loss: 2.1298 - val_accuracy: 0.3413\n",
      "Epoch 16/30\n",
      "7579/7579 - 30s - loss: 1.5787 - accuracy: 0.4843 - val_loss: 2.1313 - val_accuracy: 0.3490\n",
      "Epoch 1/30\n",
      "6981/6981 - 29s - loss: 3.0391 - accuracy: 0.1954 - val_loss: 2.5445 - val_accuracy: 0.2596\n",
      "Epoch 2/30\n",
      "6981/6981 - 28s - loss: 2.4177 - accuracy: 0.2809 - val_loss: 2.3693 - val_accuracy: 0.2811\n",
      "Epoch 3/30\n",
      "6981/6981 - 28s - loss: 2.2434 - accuracy: 0.3144 - val_loss: 2.2601 - val_accuracy: 0.3078\n",
      "Epoch 4/30\n",
      "6981/6981 - 29s - loss: 2.1216 - accuracy: 0.3420 - val_loss: 2.1994 - val_accuracy: 0.3195\n",
      "Epoch 5/30\n",
      "6981/6981 - 28s - loss: 2.0328 - accuracy: 0.3632 - val_loss: 2.1675 - val_accuracy: 0.3240\n",
      "Epoch 6/30\n",
      "6981/6981 - 28s - loss: 1.9594 - accuracy: 0.3808 - val_loss: 2.1241 - val_accuracy: 0.3415\n",
      "Epoch 7/30\n",
      "6981/6981 - 28s - loss: 1.8963 - accuracy: 0.3977 - val_loss: 2.1059 - val_accuracy: 0.3467\n",
      "Epoch 8/30\n",
      "6981/6981 - 29s - loss: 1.8368 - accuracy: 0.4145 - val_loss: 2.0905 - val_accuracy: 0.3498\n",
      "Epoch 9/30\n",
      "6981/6981 - 30s - loss: 1.7846 - accuracy: 0.4307 - val_loss: 2.0737 - val_accuracy: 0.3560\n",
      "Epoch 10/30\n",
      "6981/6981 - 29s - loss: 1.7333 - accuracy: 0.4471 - val_loss: 2.0839 - val_accuracy: 0.3552\n",
      "Epoch 11/30\n",
      "6981/6981 - 28s - loss: 1.6893 - accuracy: 0.4601 - val_loss: 2.0754 - val_accuracy: 0.3580\n",
      "Epoch 12/30\n",
      "6981/6981 - 29s - loss: 1.6442 - accuracy: 0.4736 - val_loss: 2.1125 - val_accuracy: 0.3598\n",
      "Epoch 1/30\n",
      "5163/5163 - 22s - loss: 3.1979 - accuracy: 0.1739 - val_loss: 2.6877 - val_accuracy: 0.2252\n",
      "Epoch 2/30\n",
      "5163/5163 - 21s - loss: 2.4709 - accuracy: 0.2617 - val_loss: 2.4536 - val_accuracy: 0.2528\n",
      "Epoch 3/30\n",
      "5163/5163 - 21s - loss: 2.2799 - accuracy: 0.2974 - val_loss: 2.3421 - val_accuracy: 0.2756\n",
      "Epoch 4/30\n",
      "5163/5163 - 20s - loss: 2.1564 - accuracy: 0.3259 - val_loss: 2.2849 - val_accuracy: 0.2921\n",
      "Epoch 5/30\n",
      "5163/5163 - 20s - loss: 2.0670 - accuracy: 0.3466 - val_loss: 2.2416 - val_accuracy: 0.3018\n",
      "Epoch 6/30\n",
      "5163/5163 - 20s - loss: 1.9906 - accuracy: 0.3672 - val_loss: 2.2393 - val_accuracy: 0.3042\n",
      "Epoch 7/30\n",
      "5163/5163 - 21s - loss: 1.9286 - accuracy: 0.3854 - val_loss: 2.2030 - val_accuracy: 0.3101\n",
      "Epoch 8/30\n",
      "5163/5163 - 21s - loss: 1.8739 - accuracy: 0.4002 - val_loss: 2.2053 - val_accuracy: 0.3144\n",
      "Epoch 9/30\n",
      "5163/5163 - 20s - loss: 1.8254 - accuracy: 0.4152 - val_loss: 2.1885 - val_accuracy: 0.3250\n",
      "Epoch 10/30\n",
      "5163/5163 - 21s - loss: 1.7812 - accuracy: 0.4264 - val_loss: 2.1875 - val_accuracy: 0.3246\n",
      "Epoch 11/30\n",
      "5163/5163 - 20s - loss: 1.7400 - accuracy: 0.4408 - val_loss: 2.2061 - val_accuracy: 0.3150\n",
      "Epoch 12/30\n",
      "5163/5163 - 21s - loss: 1.7009 - accuracy: 0.4512 - val_loss: 2.2000 - val_accuracy: 0.3237\n",
      "Epoch 13/30\n",
      "5163/5163 - 21s - loss: 1.6664 - accuracy: 0.4642 - val_loss: 2.2362 - val_accuracy: 0.3138\n",
      "Epoch 1/30\n",
      "5022/5022 - 20s - loss: 3.2864 - accuracy: 0.1645 - val_loss: 2.7118 - val_accuracy: 0.2397\n",
      "Epoch 2/30\n",
      "5022/5022 - 20s - loss: 2.5059 - accuracy: 0.2622 - val_loss: 2.4554 - val_accuracy: 0.2649\n",
      "Epoch 3/30\n",
      "5022/5022 - 20s - loss: 2.3071 - accuracy: 0.2934 - val_loss: 2.3481 - val_accuracy: 0.2854\n",
      "Epoch 4/30\n",
      "5022/5022 - 20s - loss: 2.1801 - accuracy: 0.3214 - val_loss: 2.2712 - val_accuracy: 0.3063\n",
      "Epoch 5/30\n",
      "5022/5022 - 20s - loss: 2.0854 - accuracy: 0.3454 - val_loss: 2.2323 - val_accuracy: 0.3172\n",
      "Epoch 6/30\n",
      "5022/5022 - 20s - loss: 2.0094 - accuracy: 0.3662 - val_loss: 2.2021 - val_accuracy: 0.3186\n",
      "Epoch 7/30\n",
      "5022/5022 - 20s - loss: 1.9466 - accuracy: 0.3825 - val_loss: 2.1654 - val_accuracy: 0.3298\n",
      "Epoch 8/30\n",
      "5022/5022 - 20s - loss: 1.8870 - accuracy: 0.3999 - val_loss: 2.1808 - val_accuracy: 0.3253\n",
      "Epoch 9/30\n",
      "5022/5022 - 20s - loss: 1.8331 - accuracy: 0.4140 - val_loss: 2.1461 - val_accuracy: 0.3440\n",
      "Epoch 10/30\n",
      "5022/5022 - 20s - loss: 1.7811 - accuracy: 0.4281 - val_loss: 2.1667 - val_accuracy: 0.3379\n",
      "Epoch 11/30\n",
      "5022/5022 - 20s - loss: 1.7317 - accuracy: 0.4460 - val_loss: 2.1727 - val_accuracy: 0.3422\n",
      "Epoch 12/30\n",
      "5022/5022 - 20s - loss: 1.6887 - accuracy: 0.4590 - val_loss: 2.1922 - val_accuracy: 0.3344\n",
      "Epoch 1/30\n",
      "5724/5724 - 23s - loss: 3.1489 - accuracy: 0.1837 - val_loss: 2.5878 - val_accuracy: 0.2465\n",
      "Epoch 2/30\n",
      "5724/5724 - 23s - loss: 2.4109 - accuracy: 0.2806 - val_loss: 2.3560 - val_accuracy: 0.2784\n",
      "Epoch 3/30\n",
      "5724/5724 - 22s - loss: 2.2141 - accuracy: 0.3164 - val_loss: 2.2449 - val_accuracy: 0.3103\n",
      "Epoch 4/30\n",
      "5724/5724 - 22s - loss: 2.0888 - accuracy: 0.3463 - val_loss: 2.1892 - val_accuracy: 0.3208\n",
      "Epoch 5/30\n",
      "5724/5724 - 23s - loss: 1.9984 - accuracy: 0.3680 - val_loss: 2.1629 - val_accuracy: 0.3225\n",
      "Epoch 6/30\n",
      "5724/5724 - 23s - loss: 1.9261 - accuracy: 0.3857 - val_loss: 2.1268 - val_accuracy: 0.3295\n",
      "Epoch 7/30\n",
      "5724/5724 - 24s - loss: 1.8654 - accuracy: 0.4037 - val_loss: 2.1382 - val_accuracy: 0.3411\n",
      "Epoch 8/30\n",
      "5724/5724 - 24s - loss: 1.8125 - accuracy: 0.4173 - val_loss: 2.1166 - val_accuracy: 0.3446\n",
      "Epoch 9/30\n",
      "5724/5724 - 25s - loss: 1.7647 - accuracy: 0.4328 - val_loss: 2.1319 - val_accuracy: 0.3418\n",
      "Epoch 10/30\n",
      "5724/5724 - 24s - loss: 1.7197 - accuracy: 0.4447 - val_loss: 2.1122 - val_accuracy: 0.3534\n",
      "Epoch 11/30\n",
      "5724/5724 - 23s - loss: 1.6755 - accuracy: 0.4602 - val_loss: 2.1176 - val_accuracy: 0.3537\n",
      "Epoch 12/30\n",
      "5724/5724 - 23s - loss: 1.6348 - accuracy: 0.4718 - val_loss: 2.1142 - val_accuracy: 0.3564\n",
      "Epoch 13/30\n",
      "5724/5724 - 24s - loss: 1.5963 - accuracy: 0.4832 - val_loss: 2.1578 - val_accuracy: 0.3546\n",
      "Epoch 1/30\n",
      "5792/5792 - 23s - loss: 3.1948 - accuracy: 0.1668 - val_loss: 2.6504 - val_accuracy: 0.2271\n",
      "Epoch 2/30\n",
      "5792/5792 - 23s - loss: 2.4555 - accuracy: 0.2635 - val_loss: 2.4017 - val_accuracy: 0.2715\n",
      "Epoch 3/30\n",
      "5792/5792 - 23s - loss: 2.2522 - accuracy: 0.3010 - val_loss: 2.2882 - val_accuracy: 0.2889\n",
      "Epoch 4/30\n",
      "5792/5792 - 23s - loss: 2.1190 - accuracy: 0.3305 - val_loss: 2.2247 - val_accuracy: 0.3101\n",
      "Epoch 5/30\n",
      "5792/5792 - 24s - loss: 2.0168 - accuracy: 0.3568 - val_loss: 2.1716 - val_accuracy: 0.3219\n",
      "Epoch 6/30\n",
      "5792/5792 - 23s - loss: 1.9407 - accuracy: 0.3788 - val_loss: 2.1567 - val_accuracy: 0.3213\n",
      "Epoch 7/30\n",
      "5792/5792 - 23s - loss: 1.8756 - accuracy: 0.3936 - val_loss: 2.1476 - val_accuracy: 0.3367\n",
      "Epoch 8/30\n",
      "5792/5792 - 23s - loss: 1.8211 - accuracy: 0.4095 - val_loss: 2.1498 - val_accuracy: 0.3329\n",
      "Epoch 9/30\n",
      "5792/5792 - 23s - loss: 1.7738 - accuracy: 0.4236 - val_loss: 2.1312 - val_accuracy: 0.3355\n",
      "Epoch 10/30\n",
      "5792/5792 - 23s - loss: 1.7285 - accuracy: 0.4408 - val_loss: 2.1349 - val_accuracy: 0.3379\n",
      "Epoch 11/30\n",
      "5792/5792 - 23s - loss: 1.6881 - accuracy: 0.4521 - val_loss: 2.1245 - val_accuracy: 0.3391\n",
      "Epoch 12/30\n",
      "5792/5792 - 23s - loss: 1.6508 - accuracy: 0.4628 - val_loss: 2.1388 - val_accuracy: 0.3438\n",
      "Epoch 13/30\n",
      "5792/5792 - 24s - loss: 1.6166 - accuracy: 0.4743 - val_loss: 2.1562 - val_accuracy: 0.3358\n",
      "Epoch 14/30\n",
      "5792/5792 - 23s - loss: 1.5815 - accuracy: 0.4868 - val_loss: 2.1666 - val_accuracy: 0.3464\n",
      "Epoch 1/30\n",
      "5781/5781 - 24s - loss: 2.4449 - accuracy: 0.2869 - val_loss: 1.9524 - val_accuracy: 0.3579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "5781/5781 - 23s - loss: 1.8595 - accuracy: 0.3724 - val_loss: 1.8319 - val_accuracy: 0.3785\n",
      "Epoch 3/30\n",
      "5781/5781 - 23s - loss: 1.7576 - accuracy: 0.3995 - val_loss: 1.7746 - val_accuracy: 0.3858\n",
      "Epoch 4/30\n",
      "5781/5781 - 23s - loss: 1.6934 - accuracy: 0.4195 - val_loss: 1.7541 - val_accuracy: 0.3990\n",
      "Epoch 5/30\n",
      "5781/5781 - 23s - loss: 1.6437 - accuracy: 0.4332 - val_loss: 1.7418 - val_accuracy: 0.3975\n",
      "Epoch 6/30\n",
      "5781/5781 - 23s - loss: 1.6025 - accuracy: 0.4486 - val_loss: 1.7231 - val_accuracy: 0.4021\n",
      "Epoch 7/30\n",
      "5781/5781 - 23s - loss: 1.5670 - accuracy: 0.4612 - val_loss: 1.7135 - val_accuracy: 0.4052\n",
      "Epoch 8/30\n",
      "5781/5781 - 23s - loss: 1.5351 - accuracy: 0.4728 - val_loss: 1.7170 - val_accuracy: 0.4009\n",
      "Epoch 9/30\n",
      "5781/5781 - 23s - loss: 1.5036 - accuracy: 0.4842 - val_loss: 1.7124 - val_accuracy: 0.4112\n",
      "Epoch 10/30\n",
      "5781/5781 - 23s - loss: 1.4769 - accuracy: 0.4959 - val_loss: 1.7073 - val_accuracy: 0.4147\n",
      "Epoch 11/30\n",
      "5781/5781 - 23s - loss: 1.4490 - accuracy: 0.5073 - val_loss: 1.7236 - val_accuracy: 0.4172\n",
      "Epoch 12/30\n",
      "5781/5781 - 23s - loss: 1.4243 - accuracy: 0.5158 - val_loss: 1.7529 - val_accuracy: 0.4059\n",
      "Epoch 13/30\n",
      "5781/5781 - 23s - loss: 1.4021 - accuracy: 0.5245 - val_loss: 1.7480 - val_accuracy: 0.4144\n",
      "Epoch 1/30\n",
      "6773/6773 - 28s - loss: 2.3818 - accuracy: 0.2891 - val_loss: 1.9651 - val_accuracy: 0.3467\n",
      "Epoch 2/30\n",
      "6773/6773 - 27s - loss: 1.8674 - accuracy: 0.3681 - val_loss: 1.8790 - val_accuracy: 0.3593\n",
      "Epoch 3/30\n",
      "6773/6773 - 28s - loss: 1.7701 - accuracy: 0.3934 - val_loss: 1.8098 - val_accuracy: 0.3763\n",
      "Epoch 4/30\n",
      "6773/6773 - 30s - loss: 1.7045 - accuracy: 0.4152 - val_loss: 1.7854 - val_accuracy: 0.3813\n",
      "Epoch 5/30\n",
      "6773/6773 - 30s - loss: 1.6573 - accuracy: 0.4281 - val_loss: 1.7577 - val_accuracy: 0.3894\n",
      "Epoch 6/30\n",
      "6773/6773 - 28s - loss: 1.6178 - accuracy: 0.4421 - val_loss: 1.7587 - val_accuracy: 0.3925\n",
      "Epoch 7/30\n",
      "6773/6773 - 28s - loss: 1.5842 - accuracy: 0.4546 - val_loss: 1.7506 - val_accuracy: 0.3994\n",
      "Epoch 8/30\n",
      "6773/6773 - 28s - loss: 1.5548 - accuracy: 0.4663 - val_loss: 1.7519 - val_accuracy: 0.4001\n",
      "Epoch 9/30\n",
      "6773/6773 - 27s - loss: 1.5271 - accuracy: 0.4753 - val_loss: 1.7465 - val_accuracy: 0.4009\n",
      "Epoch 10/30\n",
      "6773/6773 - 27s - loss: 1.5005 - accuracy: 0.4863 - val_loss: 1.7524 - val_accuracy: 0.3920\n",
      "Epoch 11/30\n",
      "6773/6773 - 28s - loss: 1.4781 - accuracy: 0.4946 - val_loss: 1.7483 - val_accuracy: 0.3998\n",
      "Epoch 12/30\n",
      "6773/6773 - 27s - loss: 1.4550 - accuracy: 0.5035 - val_loss: 1.7578 - val_accuracy: 0.4075\n"
     ]
    }
   ],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience = 3)\n",
    "for count, player in enumerate(ultimateSet,0):\n",
    "    keras.backend.clear_session()\n",
    "    model = Sequential([\n",
    "        Conv2D(64, kernel_size=(2,2), padding='same', input_shape=(8, 8, 12), kernel_regularizer='l2', activation='relu'),\n",
    "        Conv2D(64, kernel_size=(2,2), padding='same', input_shape=(8, 8, 12), kernel_regularizer='l2', activation='relu'),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dense(256, activation='relu'),\n",
    "        Flatten(),\n",
    "        Dense(64, activation = 'softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(x=player[0][0], y=player[0][1], batch_size=10, epochs=30, verbose=2,validation_split=0.111, callbacks= es)\n",
    "    model.save('models/'+ str(count) +'.h5')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"dataset.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(ultimateSet, fp)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"dataset.txt\", \"rb\") as fp:   # Unpickling\n",
    "    ultimateSet = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "for count, filename in enumerate(os.listdir('models'),0):\n",
    "    models[filename] = load_model('models/' + filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214/214 [==============================] - 2s 3ms/step - loss: 2.2028 - accuracy: 0.3343\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2.3572 - accuracy: 0.3019\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2.3902 - accuracy: 0.2873\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2.2596 - accuracy: 0.3125\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2.2860 - accuracy: 0.3173\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2.2831 - accuracy: 0.3227\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2.3576 - accuracy: 0.2790\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2.3187 - accuracy: 0.3249\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2.2448 - accuracy: 0.3362\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7.2801 - accuracy: 0.2122\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7.4814 - accuracy: 0.1939\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2.2297 - accuracy: 0.3136\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2.3182 - accuracy: 0.3131\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2.3650 - accuracy: 0.2974\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2.2344 - accuracy: 0.3272\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2.5036 - accuracy: 0.2638\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2.1850 - accuracy: 0.3261\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2.3502 - accuracy: 0.3151\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2.6225 - accuracy: 0.2854\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 2.2816 - accuracy: 0.3381\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 2.2814 - accuracy: 0.3245\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 2.3583 - accuracy: 0.3005\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 2.1587 - accuracy: 0.3383\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 2.2161 - accuracy: 0.3321\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 2.2441 - accuracy: 0.3270\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 2.3430 - accuracy: 0.2911\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 2.2759 - accuracy: 0.3347\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 2.2115 - accuracy: 0.3400\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 7.0788 - accuracy: 0.2208\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 7.3030 - accuracy: 0.2090\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 2.1967 - accuracy: 0.3198\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 2.2741 - accuracy: 0.3183\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 2.3056 - accuracy: 0.3027\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 2.1880 - accuracy: 0.3222\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 2.4132 - accuracy: 0.2828\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 2.1008 - accuracy: 0.3515\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 2.2718 - accuracy: 0.3292\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 2.6078 - accuracy: 0.2892\n",
      "234/234 [==============================] - 1s 3ms/step - loss: 2.3556 - accuracy: 0.3048\n",
      "234/234 [==============================] - 1s 3ms/step - loss: 2.2237 - accuracy: 0.3176\n",
      "234/234 [==============================] - 1s 3ms/step - loss: 2.3287 - accuracy: 0.3049\n",
      "234/234 [==============================] - 1s 3ms/step - loss: 2.2197 - accuracy: 0.3258\n",
      "234/234 [==============================] - 1s 3ms/step - loss: 2.2984 - accuracy: 0.3060\n",
      "234/234 [==============================] - 1s 3ms/step - loss: 2.3481 - accuracy: 0.2958\n",
      "234/234 [==============================] - 1s 3ms/step - loss: 2.2948 - accuracy: 0.2978\n",
      "234/234 [==============================] - 1s 3ms/step - loss: 2.3247 - accuracy: 0.3117\n",
      "234/234 [==============================] - 1s 3ms/step - loss: 2.2647 - accuracy: 0.3176\n",
      "234/234 [==============================] - 1s 3ms/step - loss: 7.1621 - accuracy: 0.2050\n",
      "234/234 [==============================] - 1s 3ms/step - loss: 7.2141 - accuracy: 0.2012\n",
      "234/234 [==============================] - 1s 3ms/step - loss: 2.1053 - accuracy: 0.3402\n",
      "234/234 [==============================] - 1s 3ms/step - loss: 2.2822 - accuracy: 0.3159\n",
      "234/234 [==============================] - 1s 3ms/step - loss: 2.3476 - accuracy: 0.3004\n",
      "234/234 [==============================] - 1s 3ms/step - loss: 2.2233 - accuracy: 0.3243\n",
      "234/234 [==============================] - 1s 3ms/step - loss: 2.3854 - accuracy: 0.2857\n",
      "234/234 [==============================] - 1s 3ms/step - loss: 2.1789 - accuracy: 0.3230\n",
      "234/234 [==============================] - 1s 3ms/step - loss: 2.3271 - accuracy: 0.3033\n",
      "234/234 [==============================] - 1s 3ms/step - loss: 2.6410 - accuracy: 0.2791\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 2.3678 - accuracy: 0.3085\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 2.2328 - accuracy: 0.3189\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 2.2730 - accuracy: 0.3220\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 2.1645 - accuracy: 0.3394\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 2.2532 - accuracy: 0.3145\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 2.3156 - accuracy: 0.3052\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 2.2863 - accuracy: 0.3052\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 2.3350 - accuracy: 0.3034\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 2.2460 - accuracy: 0.3262\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 7.3700 - accuracy: 0.1908\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 7.4045 - accuracy: 0.2009\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 2.1789 - accuracy: 0.3192\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 2.1830 - accuracy: 0.3383\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 2.3048 - accuracy: 0.3164\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 2.1884 - accuracy: 0.3305\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 2.3673 - accuracy: 0.2987\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 2.1460 - accuracy: 0.3337\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 2.2982 - accuracy: 0.3208\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 2.6412 - accuracy: 0.2814\n",
      "211/211 [==============================] - 1s 3ms/step - loss: 2.4264 - accuracy: 0.2968\n",
      "211/211 [==============================] - 1s 3ms/step - loss: 2.2883 - accuracy: 0.3077\n",
      "211/211 [==============================] - 1s 3ms/step - loss: 2.3097 - accuracy: 0.3117\n",
      "211/211 [==============================] - 1s 3ms/step - loss: 2.3390 - accuracy: 0.3120\n",
      "211/211 [==============================] - 1s 3ms/step - loss: 2.2699 - accuracy: 0.3117\n",
      "211/211 [==============================] - 1s 3ms/step - loss: 2.3521 - accuracy: 0.3047\n",
      "211/211 [==============================] - 1s 3ms/step - loss: 2.2883 - accuracy: 0.3108\n",
      "211/211 [==============================] - 1s 3ms/step - loss: 2.3582 - accuracy: 0.3121\n",
      "211/211 [==============================] - 1s 3ms/step - loss: 2.2462 - accuracy: 0.3251\n",
      "211/211 [==============================] - 1s 3ms/step - loss: 7.0529 - accuracy: 0.1934\n",
      "211/211 [==============================] - 1s 3ms/step - loss: 7.1774 - accuracy: 0.2188\n",
      "211/211 [==============================] - 1s 3ms/step - loss: 2.2207 - accuracy: 0.3245\n",
      "211/211 [==============================] - 1s 3ms/step - loss: 2.2959 - accuracy: 0.3184\n",
      "211/211 [==============================] - 1s 3ms/step - loss: 2.1910 - accuracy: 0.3429\n",
      "211/211 [==============================] - 1s 3ms/step - loss: 2.2328 - accuracy: 0.3249\n",
      "211/211 [==============================] - 1s 3ms/step - loss: 2.3557 - accuracy: 0.3010\n",
      "211/211 [==============================] - 1s 3ms/step - loss: 2.1555 - accuracy: 0.3240\n",
      "211/211 [==============================] - 1s 3ms/step - loss: 2.2925 - accuracy: 0.3316\n",
      "211/211 [==============================] - 1s 3ms/step - loss: 2.5492 - accuracy: 0.2998\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 2.4016 - accuracy: 0.3121\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 2.2794 - accuracy: 0.3164\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 2.3423 - accuracy: 0.3107\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 2.3521 - accuracy: 0.3034\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 2.2495 - accuracy: 0.3211\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 2.3632 - accuracy: 0.2972\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 2.3385 - accuracy: 0.2926\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 2.3790 - accuracy: 0.3050\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 2.2755 - accuracy: 0.3223\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 7.1723 - accuracy: 0.2067\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 7.3032 - accuracy: 0.2029\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 2.2380 - accuracy: 0.3193\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 2.3258 - accuracy: 0.3100\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 2.4163 - accuracy: 0.2941\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 2.1926 - accuracy: 0.3340\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 2.4347 - accuracy: 0.2842\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 2.2021 - accuracy: 0.3180\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 2.3728 - accuracy: 0.3120\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 2.6701 - accuracy: 0.2725\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 2.4505 - accuracy: 0.2863\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 2.2393 - accuracy: 0.3217\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 2.3015 - accuracy: 0.3096\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 2.2887 - accuracy: 0.3303\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 2.2386 - accuracy: 0.3305\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 2.2811 - accuracy: 0.3125\n",
      "226/226 [==============================] - 1s 4ms/step - loss: 2.2857 - accuracy: 0.3048\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 2.4137 - accuracy: 0.2806\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 2.2754 - accuracy: 0.3071\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 6.8681 - accuracy: 0.2051\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 6.9154 - accuracy: 0.2324\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 2.2150 - accuracy: 0.3199\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 2.2869 - accuracy: 0.3165\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 2.3291 - accuracy: 0.3082\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 2.2680 - accuracy: 0.3076\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 2.0782 - accuracy: 0.3737\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 2.1537 - accuracy: 0.3179\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 2.2802 - accuracy: 0.3235\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 2.5768 - accuracy: 0.2859\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 2.3983 - accuracy: 0.3024\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 2.2431 - accuracy: 0.3241\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 2.3389 - accuracy: 0.3021\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 2.3322 - accuracy: 0.3114\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 2.2346 - accuracy: 0.3246\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 2.2883 - accuracy: 0.3114\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 2.3185 - accuracy: 0.3086\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 2.3303 - accuracy: 0.3141\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 2.2438 - accuracy: 0.3248\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 7.3680 - accuracy: 0.1944\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 7.5390 - accuracy: 0.2040\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 2.2456 - accuracy: 0.3044\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 2.3078 - accuracy: 0.3049\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 2.3459 - accuracy: 0.3010\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 2.2690 - accuracy: 0.3150\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 2.4234 - accuracy: 0.2826\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 2.0769 - accuracy: 0.3415\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 2.3237 - accuracy: 0.3111\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 2.6743 - accuracy: 0.2788\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 2.3470 - accuracy: 0.3104\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 2.2165 - accuracy: 0.3248\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 2.2730 - accuracy: 0.3157\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 2.2708 - accuracy: 0.3220\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 2.2161 - accuracy: 0.3328\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 2.3000 - accuracy: 0.3040\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 2.2826 - accuracy: 0.3015\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 2.3075 - accuracy: 0.2979\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 2.2258 - accuracy: 0.3236\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 6.6988 - accuracy: 0.2205\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 6.9246 - accuracy: 0.2286\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 2.1998 - accuracy: 0.3157\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 2.2689 - accuracy: 0.3111\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 2.2785 - accuracy: 0.3167\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 2.1891 - accuracy: 0.3312\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 2.3382 - accuracy: 0.3081\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 2.1314 - accuracy: 0.3345\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 2.1132 - accuracy: 0.3640\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 2.4441 - accuracy: 0.3050\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 2.4380 - accuracy: 0.2941\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 2.2749 - accuracy: 0.3113\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 2.2940 - accuracy: 0.3095\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 2.3751 - accuracy: 0.2985\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 2.2395 - accuracy: 0.3137\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 2.3421 - accuracy: 0.2969\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 2.3576 - accuracy: 0.2971\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 2.3132 - accuracy: 0.3014\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 2.3307 - accuracy: 0.3021\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 3.2306 - accuracy: 0.3188\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 3.2376 - accuracy: 0.3319\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 2.2248 - accuracy: 0.3072\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 2.3159 - accuracy: 0.3077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299/299 [==============================] - 1s 3ms/step - loss: 2.3408 - accuracy: 0.3049\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 2.2418 - accuracy: 0.3082\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 2.3709 - accuracy: 0.3006\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 2.1889 - accuracy: 0.3145\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 2.2659 - accuracy: 0.3288\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 2.0322 - accuracy: 0.3637\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 2.4415 - accuracy: 0.2958\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 2.2700 - accuracy: 0.2997\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 2.1979 - accuracy: 0.3373\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 2.3780 - accuracy: 0.3020\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 2.2513 - accuracy: 0.3156\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 2.3395 - accuracy: 0.2983\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 2.3931 - accuracy: 0.2848\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 2.3291 - accuracy: 0.2860\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 2.3938 - accuracy: 0.2964\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 2.3055 - accuracy: 0.3113\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 7.3978 - accuracy: 0.2042\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 2.2333 - accuracy: 0.3107\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 2.3354 - accuracy: 0.2998\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 2.3800 - accuracy: 0.2918\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 2.2282 - accuracy: 0.3148\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 2.3768 - accuracy: 0.2914\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 2.1966 - accuracy: 0.3142\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 2.3613 - accuracy: 0.3017\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 2.6623 - accuracy: 0.2761\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2.4714 - accuracy: 0.2911\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2.3083 - accuracy: 0.3005\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2.3616 - accuracy: 0.2906\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2.2034 - accuracy: 0.3366\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2.2442 - accuracy: 0.3230\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2.3185 - accuracy: 0.2958\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2.4165 - accuracy: 0.2787\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2.3243 - accuracy: 0.3012\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2.3946 - accuracy: 0.2963\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2.2885 - accuracy: 0.3072\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7.4512 - accuracy: 0.1915\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2.2541 - accuracy: 0.3039\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2.3360 - accuracy: 0.2988\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2.3658 - accuracy: 0.3093\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2.2725 - accuracy: 0.3141\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2.3533 - accuracy: 0.2954\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2.2168 - accuracy: 0.3036\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2.3736 - accuracy: 0.3090\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 2.7084 - accuracy: 0.2692\n",
      "296/296 [==============================] - 1s 3ms/step - loss: 2.4658 - accuracy: 0.2904\n",
      "296/296 [==============================] - 1s 3ms/step - loss: 2.3163 - accuracy: 0.3196\n",
      "296/296 [==============================] - 1s 3ms/step - loss: 2.4091 - accuracy: 0.2875\n",
      "296/296 [==============================] - 1s 3ms/step - loss: 2.3823 - accuracy: 0.2973\n",
      "296/296 [==============================] - 1s 3ms/step - loss: 2.1443 - accuracy: 0.3420\n",
      "296/296 [==============================] - 1s 3ms/step - loss: 2.3596 - accuracy: 0.2985\n",
      "296/296 [==============================] - 1s 3ms/step - loss: 2.4036 - accuracy: 0.2882\n",
      "296/296 [==============================] - 1s 3ms/step - loss: 2.3969 - accuracy: 0.2836\n",
      "296/296 [==============================] - 1s 3ms/step - loss: 2.4047 - accuracy: 0.2903\n",
      "296/296 [==============================] - 1s 3ms/step - loss: 2.3345 - accuracy: 0.3047\n",
      "296/296 [==============================] - 1s 3ms/step - loss: 7.5883 - accuracy: 0.1925\n",
      "296/296 [==============================] - 1s 3ms/step - loss: 7.7118 - accuracy: 0.1850\n",
      "296/296 [==============================] - 1s 3ms/step - loss: 2.3617 - accuracy: 0.3033\n",
      "296/296 [==============================] - 1s 3ms/step - loss: 2.4617 - accuracy: 0.2842\n",
      "296/296 [==============================] - 1s 3ms/step - loss: 2.2836 - accuracy: 0.3170\n",
      "296/296 [==============================] - 1s 3ms/step - loss: 2.4858 - accuracy: 0.2729\n",
      "296/296 [==============================] - 1s 3ms/step - loss: 2.2514 - accuracy: 0.3070\n",
      "296/296 [==============================] - 1s 3ms/step - loss: 2.4632 - accuracy: 0.2894\n",
      "296/296 [==============================] - 1s 3ms/step - loss: 2.8178 - accuracy: 0.2574\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 2.4149 - accuracy: 0.3101\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 2.2140 - accuracy: 0.3488\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 2.3659 - accuracy: 0.3105\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 2.3764 - accuracy: 0.3035\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 2.2503 - accuracy: 0.3222\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 2.1060 - accuracy: 0.3613\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 2.3178 - accuracy: 0.3106\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 2.3841 - accuracy: 0.2777\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 2.3433 - accuracy: 0.3232\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 2.2782 - accuracy: 0.3360\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 7.2978 - accuracy: 0.2123\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 7.4742 - accuracy: 0.2010\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 2.2638 - accuracy: 0.3056\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 2.3707 - accuracy: 0.3045\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 2.2545 - accuracy: 0.3178\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 2.4519 - accuracy: 0.2832\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 2.1669 - accuracy: 0.3383\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 2.4083 - accuracy: 0.3033\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 2.7129 - accuracy: 0.2751\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 2.4267 - accuracy: 0.3064\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 2.3191 - accuracy: 0.3023\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 2.4194 - accuracy: 0.2882\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 2.4525 - accuracy: 0.2703\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 2.3193 - accuracy: 0.2923\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 2.3769 - accuracy: 0.2994\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 2.2484 - accuracy: 0.3166\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 2.4630 - accuracy: 0.2611\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 2.4166 - accuracy: 0.2983\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 2.3435 - accuracy: 0.3147\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 6.9217 - accuracy: 0.2098\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 7.2178 - accuracy: 0.1976\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 2.3362 - accuracy: 0.2847\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 2.4020 - accuracy: 0.2823\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 2.3360 - accuracy: 0.2910\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 2.5536 - accuracy: 0.2524\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 2.2432 - accuracy: 0.3106\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 2.3977 - accuracy: 0.2913\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 2.5786 - accuracy: 0.2862\n",
      "197/197 [==============================] - 1s 3ms/step - loss: 2.4723 - accuracy: 0.2959\n",
      "197/197 [==============================] - 1s 3ms/step - loss: 2.3061 - accuracy: 0.3045\n",
      "197/197 [==============================] - 1s 3ms/step - loss: 2.3724 - accuracy: 0.2984\n",
      "197/197 [==============================] - 1s 3ms/step - loss: 2.3551 - accuracy: 0.3206\n",
      "197/197 [==============================] - 1s 3ms/step - loss: 2.3144 - accuracy: 0.3201\n",
      "197/197 [==============================] - 1s 3ms/step - loss: 2.3423 - accuracy: 0.3004\n",
      "197/197 [==============================] - 1s 3ms/step - loss: 2.3879 - accuracy: 0.2956\n",
      "197/197 [==============================] - 1s 3ms/step - loss: 2.2166 - accuracy: 0.3338\n",
      "197/197 [==============================] - 1s 3ms/step - loss: 2.3848 - accuracy: 0.3035\n",
      "197/197 [==============================] - 1s 3ms/step - loss: 2.3154 - accuracy: 0.3144\n",
      "197/197 [==============================] - 1s 3ms/step - loss: 7.3547 - accuracy: 0.1974\n",
      "197/197 [==============================] - 1s 3ms/step - loss: 7.4442 - accuracy: 0.2118\n",
      "197/197 [==============================] - 1s 3ms/step - loss: 2.2327 - accuracy: 0.3190\n",
      "197/197 [==============================] - 1s 3ms/step - loss: 2.3162 - accuracy: 0.3236\n",
      "197/197 [==============================] - 1s 3ms/step - loss: 2.3545 - accuracy: 0.3139\n",
      "197/197 [==============================] - 1s 3ms/step - loss: 2.3391 - accuracy: 0.3126\n",
      "197/197 [==============================] - 1s 3ms/step - loss: 2.2050 - accuracy: 0.3144\n",
      "197/197 [==============================] - 1s 3ms/step - loss: 2.3962 - accuracy: 0.3163\n",
      "197/197 [==============================] - 1s 3ms/step - loss: 2.6483 - accuracy: 0.2874\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 2.3517 - accuracy: 0.3095\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 2.1972 - accuracy: 0.3327\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 2.3393 - accuracy: 0.2990\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 2.3652 - accuracy: 0.3057\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 2.2480 - accuracy: 0.3046\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 2.2458 - accuracy: 0.3194\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 2.2984 - accuracy: 0.3119\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 2.3685 - accuracy: 0.2755\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 2.1433 - accuracy: 0.3568\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 2.2453 - accuracy: 0.3331\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 7.1683 - accuracy: 0.2104\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 7.3182 - accuracy: 0.1991\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 2.2500 - accuracy: 0.2996\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 2.3020 - accuracy: 0.2908\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 2.3780 - accuracy: 0.2920\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 2.2597 - accuracy: 0.3098\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 2.1483 - accuracy: 0.3310\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 2.3739 - accuracy: 0.3055\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 2.6078 - accuracy: 0.2722\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 2.4198 - accuracy: 0.3004\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 2.2999 - accuracy: 0.3124\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 2.3738 - accuracy: 0.2912\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 2.3760 - accuracy: 0.2966\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 2.2841 - accuracy: 0.3129\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 2.3534 - accuracy: 0.3006\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 2.3679 - accuracy: 0.2986\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 2.3621 - accuracy: 0.2871\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 2.3758 - accuracy: 0.2991\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 2.1774 - accuracy: 0.3360\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 7.5370 - accuracy: 0.1945\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 7.8119 - accuracy: 0.1929\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 2.2745 - accuracy: 0.3041\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 2.3644 - accuracy: 0.2914\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 2.4097 - accuracy: 0.3013\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 2.2910 - accuracy: 0.3128\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 2.4564 - accuracy: 0.2867\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 2.3790 - accuracy: 0.3073\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 2.7139 - accuracy: 0.2792\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 2.3527 - accuracy: 0.3102\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 2.2108 - accuracy: 0.3383\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 2.2967 - accuracy: 0.3019\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 2.3874 - accuracy: 0.2915\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 2.2441 - accuracy: 0.3156\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 2.2714 - accuracy: 0.3186\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 2.3024 - accuracy: 0.3140\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 2.3926 - accuracy: 0.2761\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 2.2357 - accuracy: 0.3337\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 2.2735 - accuracy: 0.3244\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 1.7811 - accuracy: 0.4091\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 1.8023 - accuracy: 0.3787\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 2.1798 - accuracy: 0.3122\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 2.2978 - accuracy: 0.3053\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 2.3759 - accuracy: 0.2940\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 2.1895 - accuracy: 0.3189\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 2.4025 - accuracy: 0.2948\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 2.1819 - accuracy: 0.3240\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 1.9536 - accuracy: 0.3635\n",
      "265/265 [==============================] - 1s 3ms/step - loss: 2.4252 - accuracy: 0.3005\n",
      "265/265 [==============================] - 1s 3ms/step - loss: 2.2455 - accuracy: 0.3288\n",
      "265/265 [==============================] - 1s 3ms/step - loss: 2.2832 - accuracy: 0.3146\n",
      "265/265 [==============================] - 1s 4ms/step - loss: 2.3895 - accuracy: 0.3016\n",
      "265/265 [==============================] - 1s 3ms/step - loss: 2.2601 - accuracy: 0.3231\n",
      "265/265 [==============================] - 1s 3ms/step - loss: 2.3028 - accuracy: 0.3127\n",
      "265/265 [==============================] - 1s 3ms/step - loss: 2.3525 - accuracy: 0.3019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265/265 [==============================] - 1s 3ms/step - loss: 2.3358 - accuracy: 0.2982\n",
      "265/265 [==============================] - 1s 3ms/step - loss: 2.3071 - accuracy: 0.3129\n",
      "265/265 [==============================] - 1s 3ms/step - loss: 2.2908 - accuracy: 0.3220\n",
      "265/265 [==============================] - 1s 3ms/step - loss: 1.9160 - accuracy: 0.3774\n",
      "265/265 [==============================] - 1s 3ms/step - loss: 1.7152 - accuracy: 0.4126\n",
      "265/265 [==============================] - 1s 3ms/step - loss: 2.2080 - accuracy: 0.3220\n",
      "265/265 [==============================] - 1s 3ms/step - loss: 2.2780 - accuracy: 0.3290\n",
      "265/265 [==============================] - 1s 3ms/step - loss: 2.3082 - accuracy: 0.3256\n",
      "265/265 [==============================] - 1s 3ms/step - loss: 2.2193 - accuracy: 0.3234\n",
      "265/265 [==============================] - 1s 3ms/step - loss: 2.3504 - accuracy: 0.3058\n",
      "265/265 [==============================] - 1s 3ms/step - loss: 2.2049 - accuracy: 0.3262\n",
      "265/265 [==============================] - 1s 3ms/step - loss: 2.2691 - accuracy: 0.3284\n"
     ]
    }
   ],
   "source": [
    "results=[]\n",
    "for count, x in enumerate(ultimateSet,0):\n",
    "    average = 0\n",
    "    loss = 0\n",
    "    for model in models:\n",
    "        if model != str(count):\n",
    "            result = models[model].evaluate(x=ultimateSet[count][1][0], y=ultimateSet[count][1][1])\n",
    "            average = result[1] + average\n",
    "            loss = result[0] + loss\n",
    "    results.append([(average/19), (loss/19)])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.298096826201991, 2.8563139689596078],\n",
       " [0.3090392508004841, 2.795281585894133],\n",
       " [0.2979099515237306, 2.817120677546451],\n",
       " [0.30389441157642166, 2.818764899906359],\n",
       " [0.3037868785230737, 2.8106112480163574],\n",
       " [0.2965460733363503, 2.8583698147221615],\n",
       " [0.3038999838264365, 2.776106784218236],\n",
       " [0.2979629322102195, 2.8579796740883276],\n",
       " [0.3088471113066924, 2.7381981172059713],\n",
       " [0.31108451360150385, 2.3902462030711926],\n",
       " [0.29641348515686233, 2.603748685435245],\n",
       " [0.2955761763610338, 2.6138354477129484],\n",
       " [0.2847862416192105, 2.949597057543303],\n",
       " [0.3023676629129209, 2.86588884654798],\n",
       " [0.28187623776887594, 2.8827398199784127],\n",
       " [0.2991345493417037, 2.882010484996595],\n",
       " [0.29783601980460317, 2.821524406734266],\n",
       " [0.2897427309500544, 2.9277924612948767],\n",
       " [0.32236022384543167, 2.2174609523070488],\n",
       " [0.3245748720671001, 2.245341131561681]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlsxwriter\n",
    "\n",
    "\n",
    "with xlsxwriter.Workbook('groupResults.xlsx') as workbook:\n",
    "    worksheet = workbook.add_worksheet()\n",
    "\n",
    "    for row_num, data in enumerate(results):\n",
    "        worksheet.write_row(row_num, 0, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214/214 [==============================] - 1s 3ms/step - loss: 2.1949 - accuracy: 0.3552\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 2.0362 - accuracy: 0.3754\n",
      "234/234 [==============================] - 1s 3ms/step - loss: 2.3337 - accuracy: 0.2956\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 2.2885 - accuracy: 0.3168\n",
      "211/211 [==============================] - 1s 3ms/step - loss: 2.2258 - accuracy: 0.3347\n",
      "243/243 [==============================] - 1s 3ms/step - loss: 2.3207 - accuracy: 0.3035\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 2.4043 - accuracy: 0.2733\n",
      "282/282 [==============================] - 1s 3ms/step - loss: 2.3309 - accuracy: 0.2967\n",
      "225/225 [==============================] - 1s 3ms/step - loss: 2.3390 - accuracy: 0.3082\n",
      "299/299 [==============================] - 1s 3ms/step - loss: 2.2834 - accuracy: 0.3193\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 7.2071 - accuracy: 0.2003\n",
      "214/214 [==============================] - 1s 3ms/step - loss: 7.5578 - accuracy: 0.1950\n",
      "296/296 [==============================] - 1s 3ms/step - loss: 2.2938 - accuracy: 0.2959\n",
      "273/273 [==============================] - 1s 3ms/step - loss: 2.3202 - accuracy: 0.3089\n",
      "202/202 [==============================] - 1s 3ms/step - loss: 2.4436 - accuracy: 0.2918\n",
      "197/197 [==============================] - 1s 3ms/step - loss: 2.2550 - accuracy: 0.3243\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 2.5122 - accuracy: 0.2676\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 2.2002 - accuracy: 0.3234\n",
      "226/226 [==============================] - 1s 3ms/step - loss: 2.3071 - accuracy: 0.3196\n",
      "265/265 [==============================] - 1s 3ms/step - loss: 1.9646 - accuracy: 0.3777\n"
     ]
    }
   ],
   "source": [
    "results2=[]\n",
    "for count, x in enumerate(ultimateSet,0):\n",
    "    average = 0\n",
    "    loss = 0\n",
    "    for model in models:\n",
    "        if model == str(count):\n",
    "            result2 = models[model].evaluate(x=ultimateSet[count][1][0], y=ultimateSet[count][1][1])\n",
    "            average = result2[1] + average\n",
    "            loss = result2[0] + loss\n",
    "    results2.append([(average), (loss)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.355168879032135, 2.1948766708374023],\n",
       " [0.3754466474056244, 2.0361809730529785],\n",
       " [0.2955579459667206, 2.3337175846099854],\n",
       " [0.316767156124115, 2.288484811782837],\n",
       " [0.3347199559211731, 2.225780487060547],\n",
       " [0.3034864366054535, 2.3207247257232666],\n",
       " [0.2732686996459961, 2.4043312072753906],\n",
       " [0.2966996431350708, 2.3309249877929688],\n",
       " [0.3081953525543213, 2.339031934738159],\n",
       " [0.3193250894546509, 2.283437728881836],\n",
       " [0.2003408670425415, 7.2070722579956055],\n",
       " [0.19502560794353485, 7.557763576507568],\n",
       " [0.2958504855632782, 2.2938451766967773],\n",
       " [0.30888253450393677, 2.320241689682007],\n",
       " [0.2918022572994232, 2.443615674972534],\n",
       " [0.32425111532211304, 2.255000114440918],\n",
       " [0.2675800323486328, 2.512230157852173],\n",
       " [0.3234318792819977, 2.200247287750244],\n",
       " [0.31958478689193726, 2.307126045227051],\n",
       " [0.3776727616786957, 1.964587926864624]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlsxwriter\n",
    "\n",
    "\n",
    "with xlsxwriter.Workbook('selfResults.xlsx') as workbook:\n",
    "    worksheet = workbook.add_worksheet()\n",
    "\n",
    "    for row_num, data in enumerate(results2):\n",
    "        worksheet.write_row(row_num, 0, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "12\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "62\n",
      "r n b q k b . r\n",
      "p p p p p p p p\n",
      ". . . . . n . .\n",
      ". . . . . . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "r n b q k b . r\n",
      "p p p p p p p p\n",
      ". . . . . n . .\n",
      ". . . . . . . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "28\n",
      "r n b q k b . r\n",
      "p p p p p p p p\n",
      ". . . . . n . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "r n b q k b . r\n",
      "p p p p p p p p\n",
      ". . . . . n . .\n",
      ". . . . P . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "45\n",
      "r n b q k b . r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . n P . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "r n b q k b . r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . n P . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P . P P P\n",
      "R N B Q K B N R\n",
      "11\n",
      "r n b q k b . r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . n P . . .\n",
      ". . . P . . . .\n",
      ". . . . . . . .\n",
      "P P P . . P P P\n",
      "R N B Q K B N R\n",
      "r n b q k b . r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . n P . . .\n",
      ". . . P . . . .\n",
      ". . . . . . . .\n",
      "P P P . . P P P\n",
      "R N B Q K B N R\n",
      "51\n",
      "r n b q k b . r\n",
      "p p p . p p p p\n",
      ". . . p . . . .\n",
      ". . . n P . . .\n",
      ". . . P . . . .\n",
      ". . . . . . . .\n",
      "P P P . . P P P\n",
      "R N B Q K B N R\n",
      "r n b q k b . r\n",
      "p p p . p p p p\n",
      ". . . p . . . .\n",
      ". . . n P . . .\n",
      ". . . P . . . .\n",
      ". . . . . . . .\n",
      "P P P . . P P P\n",
      "R N B Q K B N R\n",
      "6\n",
      "r n b q k b . r\n",
      "p p p . p p p p\n",
      ". . . p . . . .\n",
      ". . . n P . . .\n",
      ". . . P . . . .\n",
      ". . . . . N . .\n",
      "P P P . . P P P\n",
      "R N B Q K B . R\n",
      "r n b q k b . r\n",
      "p p p . p p p p\n",
      ". . . p . . . .\n",
      ". . . n P . . .\n",
      ". . . P . . . .\n",
      ". . . . . N . .\n",
      "P P P . . P P P\n",
      "R N B Q K B . R\n",
      "58\n",
      "r n . q k b . r\n",
      "p p p . p p p p\n",
      ". . . p . . . .\n",
      ". . . n P . . .\n",
      ". . . P . . b .\n",
      ". . . . . N . .\n",
      "P P P . . P P P\n",
      "R N B Q K B . R\n",
      "r n . q k b . r\n",
      "p p p . p p p p\n",
      ". . . p . . . .\n",
      ". . . n P . . .\n",
      ". . . P . . b .\n",
      ". . . . . N . .\n",
      "P P P . . P P P\n",
      "R N B Q K B . R\n",
      "5\n",
      "r n . q k b . r\n",
      "p p p . p p p p\n",
      ". . . p . . . .\n",
      ". . . n P . . .\n",
      ". . B P . . b .\n",
      ". . . . . N . .\n",
      "P P P . . P P P\n",
      "R N B Q K . . R\n",
      "r n . q k b . r\n",
      "p p p . p p p p\n",
      ". . . p . . . .\n",
      ". . . n P . . .\n",
      ". . B P . . b .\n",
      ". . . . . N . .\n",
      "P P P . . P P P\n",
      "R N B Q K . . R\n",
      "52\n",
      "r n . q k b . r\n",
      "p p p . . p p p\n",
      ". . . p p . . .\n",
      ". . . n P . . .\n",
      ". . B P . . b .\n",
      ". . . . . N . .\n",
      "P P P . . P P P\n",
      "R N B Q K . . R\n",
      "r n . q k b . r\n",
      "p p p . . p p p\n",
      ". . . p p . . .\n",
      ". . . n P . . .\n",
      ". . B P . . b .\n",
      ". . . . . N . .\n",
      "P P P . . P P P\n",
      "R N B Q K . . R\n",
      "4\n",
      "r n . q k b . r\n",
      "p p p . . p p p\n",
      ". . . p p . . .\n",
      ". . . n P . . .\n",
      ". . B P . . b .\n",
      ". . . . . N . .\n",
      "P P P . . P P P\n",
      "R N B Q . R K .\n",
      "r n . q k b . r\n",
      "p p p . . p p p\n",
      ". . . p p . . .\n",
      ". . . n P . . .\n",
      ". . B P . . b .\n",
      ". . . . . N . .\n",
      "P P P . . P P P\n",
      "R N B Q . R K .\n",
      "35\n",
      "r n . q k b . r\n",
      "p p p . . p p p\n",
      ". n . p p . . .\n",
      ". . . . P . . .\n",
      ". . B P . . b .\n",
      ". . . . . N . .\n",
      "P P P . . P P P\n",
      "R N B Q . R K .\n",
      "r n . q k b . r\n",
      "p p p . . p p p\n",
      ". n . p p . . .\n",
      ". . . . P . . .\n",
      ". . B P . . b .\n",
      ". . . . . N . .\n",
      "P P P . . P P P\n",
      "R N B Q . R K .\n",
      "26\n",
      "r n . q k b . r\n",
      "p p p . . p p p\n",
      ". n . p p . . .\n",
      ". . . . P . . .\n",
      ". . . P . . b .\n",
      ". . . . . N . .\n",
      "P P P . B P P P\n",
      "R N B Q . R K .\n",
      "r n . q k b . r\n",
      "p p p . . p p p\n",
      ". n . p p . . .\n",
      ". . . . P . . .\n",
      ". . . P . . b .\n",
      ". . . . . N . .\n",
      "P P P . B P P P\n",
      "R N B Q . R K .\n",
      "61\n",
      "r n . q k . . r\n",
      "p p p . b p p p\n",
      ". n . p p . . .\n",
      ". . . . P . . .\n",
      ". . . P . . b .\n",
      ". . . . . N . .\n",
      "P P P . B P P P\n",
      "R N B Q . R K .\n",
      "r n . q k . . r\n",
      "p p p . b p p p\n",
      ". n . p p . . .\n",
      ". . . . P . . .\n",
      ". . . P . . b .\n",
      ". . . . . N . .\n",
      "P P P . B P P P\n",
      "R N B Q . R K .\n",
      "15\n",
      "r n . q k . . r\n",
      "p p p . b p p p\n",
      ". n . p p . . .\n",
      ". . . . P . . .\n",
      ". . . P . . b .\n",
      ". . . . . N . P\n",
      "P P P . B P P .\n",
      "R N B Q . R K .\n",
      "r n . q k . . r\n",
      "p p p . b p p p\n",
      ". n . p p . . .\n",
      ". . . . P . . .\n",
      ". . . P . . b .\n",
      ". . . . . N . P\n",
      "P P P . B P P .\n",
      "R N B Q . R K .\n",
      "30\n",
      "r n . q k . . r\n",
      "p p p . b p p p\n",
      ". n . p p . . .\n",
      ". . . . P . . b\n",
      ". . . P . . . .\n",
      ". . . . . N . P\n",
      "P P P . B P P .\n",
      "R N B Q . R K .\n",
      "r n . q k . . r\n",
      "p p p . b p p p\n",
      ". n . p p . . .\n",
      ". . . . P . . b\n",
      ". . . P . . . .\n",
      ". . . . . N . P\n",
      "P P P . B P P .\n",
      "R N B Q . R K .\n",
      "2\n",
      "r n . q k . . r\n",
      "p p p . b p p p\n",
      ". n . p p . . .\n",
      ". . . . P . . b\n",
      ". . . P . B . .\n",
      ". . . . . N . P\n",
      "P P P . B P P .\n",
      "R N . Q . R K .\n",
      "r n . q k . . r\n",
      "p p p . b p p p\n",
      ". n . p p . . .\n",
      ". . . . P . . b\n",
      ". . . P . B . .\n",
      ". . . . . N . P\n",
      "P P P . B P P .\n",
      "R N . Q . R K .\n",
      "57\n",
      "r . . q k . . r\n",
      "p p p . b p p p\n",
      ". n n p p . . .\n",
      ". . . . P . . b\n",
      ". . . P . B . .\n",
      ". . . . . N . P\n",
      "P P P . B P P .\n",
      "R N . Q . R K .\n",
      "r . . q k . . r\n",
      "p p p . b p p p\n",
      ". n n p p . . .\n",
      ". . . . P . . b\n",
      ". . . P . B . .\n",
      ". . . . . N . P\n",
      "P P P . B P P .\n",
      "R N . Q . R K .\n",
      "10\n",
      "r . . q k . . r\n",
      "p p p . b p p p\n",
      ". n n p p . . .\n",
      ". . . . P . . b\n",
      ". . . P . B . .\n",
      ". . P . . N . P\n",
      "P P . . B P P .\n",
      "R N . Q . R K .\n",
      "r . . q k . . r\n",
      "p p p . b p p p\n",
      ". n n p p . . .\n",
      ". . . . P . . b\n",
      ". . . P . B . .\n",
      ". . P . . N . P\n",
      "P P . . B P P .\n",
      "R N . Q . R K .\n",
      "60\n",
      "r . . q . r k .\n",
      "p p p . b p p p\n",
      ". n n p p . . .\n",
      ". . . . P . . b\n",
      ". . . P . B . .\n",
      ". . P . . N . P\n",
      "P P . . B P P .\n",
      "R N . Q . R K .\n",
      "r . . q . r k .\n",
      "p p p . b p p p\n",
      ". n n p p . . .\n",
      ". . . . P . . b\n",
      ". . . P . B . .\n",
      ". . P . . N . P\n",
      "P P . . B P P .\n",
      "R N . Q . R K .\n",
      "1\n",
      "r . . q . r k .\n",
      "p p p . b p p p\n",
      ". n n p p . . .\n",
      ". . . . P . . b\n",
      ". . . P . B . .\n",
      ". . P . . N . P\n",
      "P P . N B P P .\n",
      "R . . Q . R K .\n",
      "r . . q . r k .\n",
      "p p p . b p p p\n",
      ". n n p p . . .\n",
      ". . . . P . . b\n",
      ". . . P . B . .\n",
      ". . P . . N . P\n",
      "P P . N B P P .\n",
      "R . . Q . R K .\n",
      "43\n",
      "r . . q . r k .\n",
      "p p p . b p p p\n",
      ". n n . p . . .\n",
      ". . . p P . . b\n",
      ". . . P . B . .\n",
      ". . P . . N . P\n",
      "P P . N B P P .\n",
      "R . . Q . R K .\n",
      "r . . q . r k .\n",
      "p p p . b p p p\n",
      ". n n . p . . .\n",
      ". . . p P . . b\n",
      ". . . P . B . .\n",
      ". . P . . N . P\n",
      "P P . N B P P .\n",
      "R . . Q . R K .\n",
      "9\n",
      "r . . q . r k .\n",
      "p p p . b p p p\n",
      ". n n . p . . .\n",
      ". . . p P . . b\n",
      ". P . P . B . .\n",
      ". . P . . N . P\n",
      "P . . N B P P .\n",
      "R . . Q . R K .\n",
      "r . . q . r k .\n",
      "p p p . b p p p\n",
      ". n n . p . . .\n",
      ". . . p P . . b\n",
      ". P . P . B . .\n",
      ". . P . . N . P\n",
      "P . . N B P P .\n",
      "R . . Q . R K .\n",
      "48\n",
      "r . . q . r k .\n",
      ". p p . b p p p\n",
      ". n n . p . . .\n",
      "p . . p P . . b\n",
      ". P . P . B . .\n",
      ". . P . . N . P\n",
      "P . . N B P P .\n",
      "R . . Q . R K .\n",
      "r . . q . r k .\n",
      ". p p . b p p p\n",
      ". n n . p . . .\n",
      "p . . p P . . b\n",
      ". P . P . B . .\n",
      ". . P . . N . P\n",
      "P . . N B P P .\n",
      "R . . Q . R K .\n",
      "8\n",
      "r . . q . r k .\n",
      ". p p . b p p p\n",
      ". n n . p . . .\n",
      "p . . p P . . b\n",
      ". P . P . B . .\n",
      "P . P . . N . P\n",
      ". . . N B P P .\n",
      "R . . Q . R K .\n",
      "r . . q . r k .\n",
      ". p p . b p p p\n",
      ". n n . p . . .\n",
      "p . . p P . . b\n",
      ". P . P . B . .\n",
      "P . P . . N . P\n",
      ". . . N B P P .\n",
      "R . . Q . R K .\n",
      "59\n",
      "r . . . . r k .\n",
      ". p p q b p p p\n",
      ". n n . p . . .\n",
      "p . . p P . . b\n",
      ". P . P . B . .\n",
      "P . P . . N . P\n",
      ". . . N B P P .\n",
      "R . . Q . R K .\n",
      "r . . . . r k .\n",
      ". p p q b p p p\n",
      ". n n . p . . .\n",
      "p . . p P . . b\n",
      ". P . P . B . .\n",
      "P . P . . N . P\n",
      ". . . N B P P .\n",
      "R . . Q . R K .\n",
      "3\n",
      "r . . . . r k .\n",
      ". p p q b p p p\n",
      ". n n . p . . .\n",
      "p . . p P . . b\n",
      ". P . P . B . .\n",
      "P . P . . N . P\n",
      ". . Q N B P P .\n",
      "R . . . . R K .\n",
      "r . . . . r k .\n",
      ". p p q b p p p\n",
      ". n n . p . . .\n",
      "p . . p P . . b\n",
      ". P . P . B . .\n",
      "P . P . . N . P\n",
      ". . Q N B P P .\n",
      "R . . . . R K .\n",
      "39\n",
      "r . . . . r k .\n",
      ". p p q b p p p\n",
      ". n n . p . b .\n",
      "p . . p P . . .\n",
      ". P . P . B . .\n",
      "P . P . . N . P\n",
      ". . Q N B P P .\n",
      "R . . . . R K .\n",
      "r . . . . r k .\n",
      ". p p q b p p p\n",
      ". n n . p . b .\n",
      "p . . p P . . .\n",
      ". P . P . B . .\n",
      "P . P . . N . P\n",
      ". . Q N B P P .\n",
      "R . . . . R K .\n",
      "12\n",
      "r . . . . r k .\n",
      ". p p q b p p p\n",
      ". n n . p . b .\n",
      "p . . p P . . .\n",
      ". P . P . B . .\n",
      "P . P B . N . P\n",
      ". . Q N . P P .\n",
      "R . . . . R K .\n",
      "r . . . . r k .\n",
      ". p p q b p p p\n",
      ". n n . p . b .\n",
      "p . . p P . . .\n",
      ". P . P . B . .\n",
      "P . P B . N . P\n",
      ". . Q N . P P .\n",
      "R . . . . R K .\n",
      "61\n",
      "r . r . . . k .\n",
      ". p p q b p p p\n",
      ". n n . p . b .\n",
      "p . . p P . . .\n",
      ". P . P . B . .\n",
      "P . P B . N . P\n",
      ". . Q N . P P .\n",
      "R . . . . R K .\n",
      "r . r . . . k .\n",
      ". p p q b p p p\n",
      ". n n . p . b .\n",
      "p . . p P . . .\n",
      ". P . P . B . .\n",
      "P . P B . N . P\n",
      ". . Q N . P P .\n",
      "R . . . . R K .\n",
      "5\n",
      "r . r . . . k .\n",
      ". p p q b p p p\n",
      ". n n . p . b .\n",
      "p . . p P . . .\n",
      ". P . P . B . .\n",
      "P . P B . N . P\n",
      ". . Q N . P P .\n",
      "R R . . . . K .\n",
      "r . r . . . k .\n",
      ". p p q b p p p\n",
      ". n n . p . b .\n",
      "p . . p P . . .\n",
      ". P . P . B . .\n",
      "P . P B . N . P\n",
      ". . Q N . P P .\n",
      "R R . . . . K .\n",
      "52\n",
      "r . r . . b k .\n",
      ". p p q . p p p\n",
      ". n n . p . b .\n",
      "p . . p P . . .\n",
      ". P . P . B . .\n",
      "P . P B . N . P\n",
      ". . Q N . P P .\n",
      "R R . . . . K .\n",
      "r . r . . b k .\n",
      ". p p q . p p p\n",
      ". n n . p . b .\n",
      "p . . p P . . .\n",
      ". P . P . B . .\n",
      "P . P B . N . P\n",
      ". . Q N . P P .\n",
      "R R . . . . K .\n",
      "23\n",
      "r . r . . b k .\n",
      ". p p q . p p p\n",
      ". n n . p . b .\n",
      "p . . p P . . .\n",
      ". P . P . B . P\n",
      "P . P B . N . .\n",
      ". . Q N . P P .\n",
      "R R . . . . K .\n",
      "r . r . . b k .\n",
      ". p p q . p p p\n",
      ". n n . p . b .\n",
      "p . . p P . . .\n",
      ". P . P . B . P\n",
      "P . P B . N . .\n",
      ". . Q N . P P .\n",
      "R R . . . . K .\n",
      "42\n",
      "r . r . . b k .\n",
      ". p p q n p p p\n",
      ". n . . p . b .\n",
      "p . . p P . . .\n",
      ". P . P . B . P\n",
      "P . P B . N . .\n",
      ". . Q N . P P .\n",
      "R R . . . . K .\n",
      "r . r . . b k .\n",
      ". p p q n p p p\n",
      ". n . . p . b .\n",
      "p . . p P . . .\n",
      ". P . P . B . P\n",
      "P . P B . N . .\n",
      ". . Q N . P P .\n",
      "R R . . . . K .\n",
      "14\n",
      "r . r . . b k .\n",
      ". p p q n p p p\n",
      ". n . . p . b .\n",
      "p . . p P . . .\n",
      ". P . P . B . P\n",
      "P . P B . N P .\n",
      ". . Q N . P . .\n",
      "R R . . . . K .\n",
      "r . r . . b k .\n",
      ". p p q n p p p\n",
      ". n . . p . b .\n",
      "p . . p P . . .\n",
      ". P . P . B . P\n",
      "P . P B . N P .\n",
      ". . Q N . P . .\n",
      "R R . . . . K .\n",
      "51\n",
      "r . r . . b k .\n",
      ". p p . n p p p\n",
      ". n . . p . b .\n",
      "p . . p P . . .\n",
      "q P . P . B . P\n",
      "P . P B . N P .\n",
      ". . Q N . P . .\n",
      "R R . . . . K .\n",
      "r . r . . b k .\n",
      ". p p . n p p p\n",
      ". n . . p . b .\n",
      "p . . p P . . .\n",
      "q P . P . B . P\n",
      "P . P B . N P .\n",
      ". . Q N . P . .\n",
      "R R . . . . K .\n",
      "21\n",
      "r . r . . b k .\n",
      ". p p . n p p p\n",
      ". n . . p . b .\n",
      "p . . p P . . .\n",
      "q P . P . B . P\n",
      "P . P B . . P .\n",
      ". . Q N . P . .\n",
      "R R . . N . K .\n",
      "r . r . . b k .\n",
      ". p p . n p p p\n",
      ". n . . p . b .\n",
      "p . . p P . . .\n",
      "q P . P . B . P\n",
      "P . P B . . P .\n",
      ". . Q N . P . .\n",
      "R R . . N . K .\n",
      "24\n",
      "r . r . . b k .\n",
      ". p p . n p p p\n",
      ". n . . p . b .\n",
      "p . . p P . . .\n",
      ". P . P . B . P\n",
      "P . P B . . P .\n",
      ". . q N . P . .\n",
      "R R . . N . K .\n",
      "r . r . . b k .\n",
      ". p p . n p p p\n",
      ". n . . p . b .\n",
      "p . . p P . . .\n",
      ". P . P . B . P\n",
      "P . P B . . P .\n",
      ". . q N . P . .\n",
      "R R . . N . K .\n",
      "19\n",
      "r . r . . b k .\n",
      ". p p . n p p p\n",
      ". n . . p . b .\n",
      "p . . p P . . .\n",
      ". P . P . B . P\n",
      "P . P . . . P .\n",
      ". . B N . P . .\n",
      "R R . . N . K .\n",
      "r . r . . b k .\n",
      ". p p . n p p p\n",
      ". n . . p . b .\n",
      "p . . p P . . .\n",
      ". P . P . B . P\n",
      "P . P . . . P .\n",
      ". . B N . P . .\n",
      "R R . . N . K .\n",
      "46\n",
      "r . r . . b k .\n",
      ". p p . n p p p\n",
      ". n . . p . . .\n",
      "p . . p P . . .\n",
      ". P . P . B . P\n",
      "P . P . . . P .\n",
      ". . b N . P . .\n",
      "R R . . N . K .\n",
      "r . r . . b k .\n",
      ". p p . n p p p\n",
      ". n . . p . . .\n",
      "p . . p P . . .\n",
      ". P . P . B . P\n",
      "P . P . . . P .\n",
      ". . b N . P . .\n",
      "R R . . N . K .\n",
      "4\n",
      "r . r . . b k .\n",
      ". p p . n p p p\n",
      ". n . . p . . .\n",
      "p . . p P . . .\n",
      ". P . P . B . P\n",
      "P . P . . . P .\n",
      ". . N N . P . .\n",
      "R R . . . . K .\n",
      "r . r . . b k .\n",
      ". p p . n p p p\n",
      ". n . . p . . .\n",
      "p . . p P . . .\n",
      ". P . P . B . P\n",
      "P . P . . . P .\n",
      ". . N N . P . .\n",
      "R R . . . . K .\n",
      "41\n",
      "r . r . . b k .\n",
      ". p p . n p p p\n",
      ". . . . p . . .\n",
      "p . . p P . . .\n",
      "n P . P . B . P\n",
      "P . P . . . P .\n",
      ". . N N . P . .\n",
      "R R . . . . K .\n",
      "r . r . . b k .\n",
      ". p p . n p p p\n",
      ". . . . p . . .\n",
      "p . . p P . . .\n",
      "n P . P . B . P\n",
      "P . P . . . P .\n",
      ". . N N . P . .\n",
      "R R . . . . K .\n",
      "1\n",
      "r . r . . b k .\n",
      ". p p . n p p p\n",
      ". . . . p . . .\n",
      "p . . p P . . .\n",
      "n P . P . B . P\n",
      "P R P . . . P .\n",
      ". . N N . P . .\n",
      "R . . . . . K .\n",
      "r . r . . b k .\n",
      ". p p . n p p p\n",
      ". . . . p . . .\n",
      "p . . p P . . .\n",
      "n P . P . B . P\n",
      "P R P . . . P .\n",
      ". . N N . P . .\n",
      "R . . . . . K .\n",
      "49\n",
      "r . r . . b k .\n",
      ". . p . n p p p\n",
      ". p . . p . . .\n",
      "p . . p P . . .\n",
      "n P . P . B . P\n",
      "P R P . . . P .\n",
      ". . N N . P . .\n",
      "R . . . . . K .\n",
      "r . r . . b k .\n",
      ". . p . n p p p\n",
      ". p . . p . . .\n",
      "p . . p P . . .\n",
      "n P . P . B . P\n",
      "P R P . . . P .\n",
      ". . N N . P . .\n",
      "R . . . . . K .\n",
      "6\n",
      "r . r . . b k .\n",
      ". . p . n p p p\n",
      ". p . . p . . .\n",
      "p . . p P . . .\n",
      "n P . P . B . P\n",
      "P R P . . . P .\n",
      ". . N N . P . .\n",
      "R . . . . K . .\n",
      "r . r . . b k .\n",
      ". . p . n p p p\n",
      ". p . . p . . .\n",
      "p . . p P . . .\n",
      "n P . P . B . P\n",
      "P R P . . . P .\n",
      ". . N N . P . .\n",
      "R . . . . K . .\n",
      "50\n",
      "r . r . . b k .\n",
      ". . . . n p p p\n",
      ". p . . p . . .\n",
      "p . p p P . . .\n",
      "n P . P . B . P\n",
      "P R P . . . P .\n",
      ". . N N . P . .\n",
      "R . . . . K . .\n",
      "r . r . . b k .\n",
      ". . . . n p p p\n",
      ". p . . p . . .\n",
      "p . p p P . . .\n",
      "n P . P . B . P\n",
      "P R P . . . P .\n",
      ". . N N . P . .\n",
      "R . . . . K . .\n",
      "25\n",
      "r . r . . b k .\n",
      ". . . . n p p p\n",
      ". p . . p . . .\n",
      "p . P p P . . .\n",
      "n . . P . B . P\n",
      "P R P . . . P .\n",
      ". . N N . P . .\n",
      "R . . . . K . .\n",
      "r . r . . b k .\n",
      ". . . . n p p p\n",
      ". p . . p . . .\n",
      "p . P p P . . .\n",
      "n . . P . B . P\n",
      "P R P . . . P .\n",
      ". . N N . P . .\n",
      "R . . . . K . .\n",
      "41\n",
      "r . r . . b k .\n",
      ". . . . n p p p\n",
      ". . . . p . . .\n",
      "p . p p P . . .\n",
      "n . . P . B . P\n",
      "P R P . . . P .\n",
      ". . N N . P . .\n",
      "R . . . . K . .\n",
      "r . r . . b k .\n",
      ". . . . n p p p\n",
      ". . . . p . . .\n",
      "p . p p P . . .\n",
      "n . . P . B . P\n",
      "P R P . . . P .\n",
      ". . N N . P . .\n",
      "R . . . . K . .\n",
      "27\n",
      "r . r . . b k .\n",
      ". . . . n p p p\n",
      ". . . . p . . .\n",
      "p . P p P . . .\n",
      "n . . . . B . P\n",
      "P R P . . . P .\n",
      ". . N N . P . .\n",
      "R . . . . K . .\n",
      "r . r . . b k .\n",
      ". . . . n p p p\n",
      ". . . . p . . .\n",
      "p . P p P . . .\n",
      "n . . . . B . P\n",
      "P R P . . . P .\n",
      ". . N N . P . .\n",
      "R . . . . K . .\n",
      "58\n",
      "r . . . . b k .\n",
      ". . . . n p p p\n",
      ". . . . p . . .\n",
      "p . r p P . . .\n",
      "n . . . . B . P\n",
      "P R P . . . P .\n",
      ". . N N . P . .\n",
      "R . . . . K . .\n",
      "r . . . . b k .\n",
      ". . . . n p p p\n",
      ". . . . p . . .\n",
      "p . r p P . . .\n",
      "n . . . . B . P\n",
      "P R P . . . P .\n",
      ". . N N . P . .\n",
      "R . . . . K . .\n",
      "11\n",
      "r . . . . b k .\n",
      ". . . . n p p p\n",
      ". . . . p . . .\n",
      "p . r p P . . .\n",
      "n . . . . B . P\n",
      "P R P . . . P .\n",
      ". . N . . P . .\n",
      "R N . . . K . .\n",
      "r . . . . b k .\n",
      ". . . . n p p p\n",
      ". . . . p . . .\n",
      "p . r p P . . .\n",
      "n . . . . B . P\n",
      "P R P . . . P .\n",
      ". . N . . P . .\n",
      "R N . . . K . .\n",
      "56\n",
      ". . r . . b k .\n",
      ". . . . n p p p\n",
      ". . . . p . . .\n",
      "p . r p P . . .\n",
      "n . . . . B . P\n",
      "P R P . . . P .\n",
      ". . N . . P . .\n",
      "R N . . . K . .\n",
      ". . r . . b k .\n",
      ". . . . n p p p\n",
      ". . . . p . . .\n",
      "p . r p P . . .\n",
      "n . . . . B . P\n",
      "P R P . . . P .\n",
      ". . N . . P . .\n",
      "R N . . . K . .\n",
      "29\n",
      ". . r . . b k .\n",
      ". . . . n p p p\n",
      ". . . . p . . .\n",
      "p . r p P . . .\n",
      "n . . . . . . P\n",
      "P R P . B . P .\n",
      ". . N . . P . .\n",
      "R N . . . K . .\n",
      ". . r . . b k .\n",
      ". . . . n p p p\n",
      ". . . . p . . .\n",
      "p . r p P . . .\n",
      "n . . . . . . P\n",
      "P R P . B . P .\n",
      ". . N . . P . .\n",
      "R N . . . K . .\n",
      "34\n",
      ". . r . . b k .\n",
      ". . . . n p p p\n",
      ". . . . p . . .\n",
      "p . . p P . . .\n",
      "n . r . . . . P\n",
      "P R P . B . P .\n",
      ". . N . . P . .\n",
      "R N . . . K . .\n",
      ". . r . . b k .\n",
      ". . . . n p p p\n",
      ". . . . p . . .\n",
      "p . . p P . . .\n",
      "n . r . . . . P\n",
      "P R P . B . P .\n",
      ". . N . . P . .\n",
      "R N . . . K . .\n",
      "20\n",
      ". . r . . b k .\n",
      ". . . . n p p p\n",
      ". . . . p . . .\n",
      "p . . p P . . .\n",
      "n . r B . . . P\n",
      "P R P . . . P .\n",
      ". . N . . P . .\n",
      "R N . . . K . .\n",
      ". . r . . b k .\n",
      ". . . . n p p p\n",
      ". . . . p . . .\n",
      "p . . p P . . .\n",
      "n . r B . . . P\n",
      "P R P . . . P .\n",
      ". . N . . P . .\n",
      "R N . . . K . .\n",
      "52\n",
      ". . r . . b k .\n",
      ". . . . . p p p\n",
      ". . n . p . . .\n",
      "p . . p P . . .\n",
      "n . r B . . . P\n",
      "P R P . . . P .\n",
      ". . N . . P . .\n",
      "R N . . . K . .\n",
      ". . r . . b k .\n",
      ". . . . . p p p\n",
      ". . n . p . . .\n",
      "p . . p P . . .\n",
      "n . r B . . . P\n",
      "P R P . . . P .\n",
      ". . N . . P . .\n",
      "R N . . . K . .\n",
      "17\n",
      ". . r . . b k .\n",
      ". . . . . p p p\n",
      ". . n . p . . .\n",
      "p R . p P . . .\n",
      "n . r B . . . P\n",
      "P . P . . . P .\n",
      ". . N . . P . .\n",
      "R N . . . K . .\n",
      ". . r . . b k .\n",
      ". . . . . p p p\n",
      ". . n . p . . .\n",
      "p R . p P . . .\n",
      "n . r B . . . P\n",
      "P . P . . . P .\n",
      ". . N . . P . .\n",
      "R N . . . K . .\n",
      "42\n",
      ". . r . . b k .\n",
      ". . . . . p p p\n",
      ". . . . p . . .\n",
      "p R . p P . . .\n",
      "n . r n . . . P\n",
      "P . P . . . P .\n",
      ". . N . . P . .\n",
      "R N . . . K . .\n",
      ". . r . . b k .\n",
      ". . . . . p p p\n",
      ". . . . p . . .\n",
      "p R . p P . . .\n",
      "n . r n . . . P\n",
      "P . P . . . P .\n",
      ". . N . . P . .\n",
      "R N . . . K . .\n",
      "10\n",
      ". . r . . b k .\n",
      ". . . . . p p p\n",
      ". . . . p . . .\n",
      "p R . p P . . .\n",
      "n . r N . . . P\n",
      "P . P . . . P .\n",
      ". . . . . P . .\n",
      "R N . . . K . .\n",
      ". . r . . b k .\n",
      ". . . . . p p p\n",
      ". . . . p . . .\n",
      "p R . p P . . .\n",
      "n . r N . . . P\n",
      "P . P . . . P .\n",
      ". . . . . P . .\n",
      "R N . . . K . .\n",
      "24\n",
      ". . r . . b k .\n",
      ". . . . . p p p\n",
      ". . . . p . . .\n",
      "p R . p P . . .\n",
      ". . r N . . . P\n",
      "P . n . . . P .\n",
      ". . . . . P . .\n",
      "R N . . . K . .\n",
      ". . r . . b k .\n",
      ". . . . . p p p\n",
      ". . . . p . . .\n",
      "p R . p P . . .\n",
      ". . r N . . . P\n",
      "P . n . . . P .\n",
      ". . . . . P . .\n",
      "R N . . . K . .\n",
      "1\n",
      ". . r . . b k .\n",
      ". . . . . p p p\n",
      ". . . . p . . .\n",
      "p R . p P . . .\n",
      ". . r N . . . P\n",
      "P . N . . . P .\n",
      ". . . . . P . .\n",
      "R . . . . K . .\n",
      ". . r . . b k .\n",
      ". . . . . p p p\n",
      ". . . . p . . .\n",
      "p R . p P . . .\n",
      ". . r N . . . P\n",
      "P . N . . . P .\n",
      ". . . . . P . .\n",
      "R . . . . K . .\n",
      "26\n",
      ". . r . . b k .\n",
      ". . . . . p p p\n",
      ". . . . p . . .\n",
      "p R . p P . . .\n",
      ". . . r . . . P\n",
      "P . N . . . P .\n",
      ". . . . . P . .\n",
      "R . . . . K . .\n",
      ". . r . . b k .\n",
      ". . . . . p p p\n",
      ". . . . p . . .\n",
      "p R . p P . . .\n",
      ". . . r . . . P\n",
      "P . N . . . P .\n",
      ". . . . . P . .\n",
      "R . . . . K . .\n",
      "18\n",
      ". . r . . b k .\n",
      ". . . . . p p p\n",
      ". . . . p . . .\n",
      "p R . p P . . .\n",
      ". . . r . . . P\n",
      "P . . . . . P .\n",
      ". . . . N P . .\n",
      "R . . . . K . .\n",
      ". . r . . b k .\n",
      ". . . . . p p p\n",
      ". . . . p . . .\n",
      "p R . p P . . .\n",
      ". . . r . . . P\n",
      "P . . . . . P .\n",
      ". . . . N P . .\n",
      "R . . . . K . .\n",
      "27\n",
      ". . r . . b k .\n",
      ". . . . . p p p\n",
      ". . . . p . . .\n",
      "p R . p P . . .\n",
      "r . . . . . . P\n",
      "P . . . . . P .\n",
      ". . . . N P . .\n",
      "R . . . . K . .\n",
      ". . r . . b k .\n",
      ". . . . . p p p\n",
      ". . . . p . . .\n",
      "p R . p P . . .\n",
      "r . . . . . . P\n",
      "P . . . . . P .\n",
      ". . . . N P . .\n",
      "R . . . . K . .\n",
      "5\n",
      ". . r . . b k .\n",
      ". . . . . p p p\n",
      ". . . . p . . .\n",
      "p R . p P . . .\n",
      "r . . . . . . P\n",
      "P . . . . . P .\n",
      ". . . . N P . .\n",
      "R . . . K . . .\n",
      ". . r . . b k .\n",
      ". . . . . p p p\n",
      ". . . . p . . .\n",
      "p R . p P . . .\n",
      "r . . . . . . P\n",
      "P . . . . . P .\n",
      ". . . . N P . .\n",
      "R . . . K . . .\n",
      "24\n",
      ". . r . . b k .\n",
      ". . . . . p p p\n",
      ". . . . p . . .\n",
      "p R . p P . . .\n",
      ". . . . . . . P\n",
      "r . . . . . P .\n",
      ". . . . N P . .\n",
      "R . . . K . . .\n",
      ". . r . . b k .\n",
      ". . . . . p p p\n",
      ". . . . p . . .\n",
      "p R . p P . . .\n",
      ". . . . . . . P\n",
      "r . . . . . P .\n",
      ". . . . N P . .\n",
      "R . . . K . . .\n",
      "0\n",
      ". . r . . b k .\n",
      ". . . . . p p p\n",
      ". . . . p . . .\n",
      "p R . p P . . .\n",
      ". . . . . . . P\n",
      "r . . . . . P .\n",
      ". . . . N P . .\n",
      ". R . . K . . .\n",
      ". . r . . b k .\n",
      ". . . . . p p p\n",
      ". . . . p . . .\n",
      "p R . p P . . .\n",
      ". . . . . . . P\n",
      "r . . . . . P .\n",
      ". . . . N P . .\n",
      ". R . . K . . .\n",
      "61\n",
      ". . r . . . k .\n",
      ". . . . . p p p\n",
      ". . . . p . . .\n",
      "p R . p P . . .\n",
      ". b . . . . . P\n",
      "r . . . . . P .\n",
      ". . . . N P . .\n",
      ". R . . K . . .\n",
      ". . r . . . k .\n",
      ". . . . . p p p\n",
      ". . . . p . . .\n",
      "p R . p P . . .\n",
      ". b . . . . . P\n",
      "r . . . . . P .\n",
      ". . . . N P . .\n",
      ". R . . K . . .\n",
      "4\n",
      ". . r . . . k .\n",
      ". . . . . p p p\n",
      ". . . . p . . .\n",
      "p R . p P . . .\n",
      ". b . . . . . P\n",
      "r . . . . . P .\n",
      ". . . . N P . .\n",
      ". R . . . K . .\n",
      ". . r . . . k .\n",
      ". . . . . p p p\n",
      ". . . . p . . .\n",
      "p R . p P . . .\n",
      ". b . . . . . P\n",
      "r . . . . . P .\n",
      ". . . . N P . .\n",
      ". R . . . K . .\n",
      "16\n",
      ". . r . . . k .\n",
      ". . . . . p p p\n",
      ". . . . p . . .\n",
      "p R . p P . . .\n",
      ". b . . . . . P\n",
      ". . . r . . P .\n",
      ". . . . N P . .\n",
      ". R . . . K . .\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-f3b4ed3a2b73>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;31m#print(board)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;31m#print(board.turn)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m \u001b[0mboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmoves\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;31m#if piece_color == board.turn:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;31m#print(board)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "pgn = open(\"Carlsen.pgn\")\n",
    "game2 = chess.pgn.read_game(pgn)\n",
    "gameNow = chess.pgn.read_game(pgn)\n",
    "piece_color = \"n.a.\"\n",
    "\n",
    "\n",
    "if re.search(\"Carlsen\", gameNow.headers[\"White\"]) != None:\n",
    "    piece_color = True\n",
    "\n",
    "elif re.search(\"Carlsen\", gameNow.headers[\"Black\"]) != None:\n",
    "    piece_color = False\n",
    "    \n",
    "if re.search(\"Carlsen\", game2.headers[\"White\"]) != None:\n",
    "    piece_color2 = True\n",
    "\n",
    "elif re.search(\"Carlsen\", game2.headers[\"Black\"]) != None:\n",
    "    piece_color2 = False\n",
    "\n",
    "moves = []\n",
    "board = gameNow.board()\n",
    "for move in gameNow.mainline_moves():\n",
    "    \n",
    "    print(board)\n",
    "    print(move.from_square)    \n",
    "    board.push(move)\n",
    "    print(board)\n",
    "\n",
    "# print(board)\n",
    "# print(piece_color)\n",
    "   \n",
    "# print(board)    \n",
    "\n",
    "moves2 = []\n",
    "for move in game2.mainline_moves():\n",
    "    moves2.append(move)\n",
    "\n",
    "#print(piece_color2)\n",
    "board2 = game2.board()  \n",
    "#print(board2)\n",
    "#print(board2.turn)\n",
    "#if piece_color2 == board.turn:\n",
    "\n",
    "\n",
    "board2.push(moves2[0])\n",
    "#if piece_color2 == board.turn:\n",
    "#print(board2)   \n",
    "#print(board2.turn)\n",
    "board2.push(moves2[1])\n",
    "#if piece_color2 == board.turn:\n",
    "#print(board2) \n",
    "#print(board2.turn)\n",
    "board2.push(moves2[2])\n",
    "#if piece_color2 == board.turn:\n",
    "#print(board2)\n",
    "#print(board2.turn)\n",
    "    \n",
    "print(\"------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "#print(piece_color)\n",
    "board = gameNow.board()   \n",
    "#if piece_color == board.turn:\n",
    "#print(board)\n",
    "#print(board.turn)\n",
    "board.push(moves[0])\n",
    "#if piece_color == board.turn:\n",
    "#print(board)   \n",
    "#print(board.turn)\n",
    "board.push(moves[1])\n",
    "#if piece_color == board.turn:\n",
    "#print(board)  \n",
    "#print(board.turn)\n",
    "board.push(moves[2])\n",
    "#if piece_color == board.turn:\n",
    "#print(board)\n",
    "#print(board.turn)\n",
    "    \n",
    "#print(first_game.headers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('items.csv', 'w', newline='') as file:\n",
    "    fieldnames = ['player_name', 'fide_rating']\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    writer.writerow({'player_name': 'Magnus Carlsen', 'fide_rating': 2870})\n",
    "    writer.writerow({'player_name': 'Fabiano Caruana', 'fide_rating': 2822})\n",
    "    writer.writerow({'player_name': 'Ding Liren', 'fide_rating': 2801})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = []\n",
    "# for x in range(0,64):\n",
    "#     output.append(0)\n",
    "    \n",
    "# transform = {\n",
    "#     \"r\" : [1,0,0,0,0,0,0,0,0,0,0,0],\n",
    "#     \"n\" : [0,1,0,0,0,0,0,0,0,0,0,0],\n",
    "#     \"b\" : [0,0,1,0,0,0,0,0,0,0,0,0],\n",
    "#     \"q\" : [0,0,0,1,0,0,0,0,0,0,0,0],\n",
    "#     \"k\" : [0,0,0,0,1,0,0,0,0,0,0,0],\n",
    "#     \"p\" : [0,0,0,0,0,1,0,0,0,0,0,0],\n",
    "#     \"P\" : [0,0,0,0,0,0,1,0,0,0,0,0],\n",
    "#     \"K\" : [0,0,0,0,0,0,0,1,0,0,0,0],\n",
    "#     \"Q\" : [0,0,0,0,0,0,0,0,1,0,0,0],\n",
    "#     \"B\" : [0,0,0,0,0,0,0,0,0,1,0,0],\n",
    "#     \"N\" : [0,0,0,0,0,0,0,0,0,0,1,0],\n",
    "#     \"R\" : [0,0,0,0,0,0,0,0,0,0,0,1],\n",
    "#     \"1\" : [[0,0,0,0,0,0,0,0,0,0,0,0]],\n",
    "#     \"2\" : [[0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0]],\n",
    "#     \"3\" : [[0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0]],\n",
    "#     \"4\" : [[0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0]],\n",
    "#     \"5\" : [[0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0]],\n",
    "#     \"6\" : [[0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0]],\n",
    "#     \"7\" : [[0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0]],\n",
    "#     \"8\" : [[0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0], [0,0,0,0,0,0,0,0,0,0,0,0]]\n",
    "# }\n",
    "\n",
    "# def GameMaker(game, piece_color):\n",
    "#     gameRun = []\n",
    "#     board = game.board()\n",
    "#     for move in game.mainline_moves():\n",
    "#         #print(board.fen())\n",
    "#         if piece_color == board.turn:\n",
    "#             gameRun.append([board.fen().split()[0], move.from_square, board.fullmove_number])\n",
    "#         board.push(move)\n",
    "    \n",
    "#     for x in range(0, len(gameRun)):\n",
    "#         gameRun[x].append(board.fullmove_number)\n",
    "\n",
    "#     return gameRun\n",
    "\n",
    "# def GameReadier(gameRun):\n",
    "#     gameRunReady = []\n",
    "#     # gamerun = gameMaker(first_game, piece_color)\n",
    "#     for move in gameRun:\n",
    "#         temp = move[0].split(\"/\")\n",
    "#         rowReady = []\n",
    "#         for row in range(0,len(temp)):\n",
    "            \n",
    "#             letterBox = []\n",
    "#             brokenList = list(str(temp[row]))\n",
    "            \n",
    "#             for letter in brokenList:\n",
    "#                 if SringIntTester(letter):  \n",
    "#                     letterBox.extend(transform[letter]) \n",
    "#                 else: \n",
    "#                     letterBox.append(transform[letter]) \n",
    "#             #print(letterBox)\n",
    "#             rowReady.append(letterBox)\n",
    "#         gameRunReady.append((rowReady, move[1], move[2], move[3]))\n",
    "#     #print(gameRunReady[0])\n",
    "#     return gameRunReady\n",
    "\n",
    "# file = open('work.csv', mode='w') \n",
    "# kopjes = ['board', 'answer', 'turn', 'totalTurns']\n",
    "# writer = csv.DictWriter(file, delimiter=',', fieldnames = kopjes, lineterminator = '\\n')\n",
    "\n",
    "\n",
    "# pgn = open(\"Carlsen.pgn\")\n",
    "# CompleteSet = []\n",
    "# while True:\n",
    "    \n",
    "#     eindeTest = chess.pgn.read_headers(pgn)\n",
    "#     if eindeTest is None:\n",
    "#         break\n",
    "\n",
    "#     gameNow = chess.pgn.read_game(pgn)\n",
    "#     piece_color = \"n.a.\"\n",
    "#     if re.search(\"Carlsen\", gameNow.headers[\"White\"]) != None:\n",
    "#         piece_color = True\n",
    "#     elif re.search(\"Carlsen\", gameNow.headers[\"Black\"]) != None:\n",
    "#         piece_color = False\n",
    "#     #print(first_game.headers)\n",
    "#     gameImpr = GameMaker(gameNow, piece_color)\n",
    "#     #print(gameImpr[1])\n",
    "#     gameDone = GameReadier(gameImpr)\n",
    "    \n",
    "#     #print(gameDone)\n",
    "    \n",
    "#     for singleBoardConfig in gameDone:\n",
    "#         outputAnswer = output[:]\n",
    "#         outputAnswer[singleBoardConfig[1]] = 1\n",
    "#         writer.writerow({'board' : singleBoardConfig[0], 'answer': outputAnswer, 'turn' : singleBoardConfig[2], 'totalTurns': singleBoardConfig[3]})\n",
    "        \n",
    "# #         CompleteSet.append({'board' : singleBoardConfig[0], 'answer': singleBoardConfig[1], 'turn' : singleBoardConfig[2]})\n",
    "# #         print(singleBoardConfig[0])\n",
    "# #         print(singleBoardConfig[1])\n",
    "# #         print(singleBoardConfig[2])\n",
    "\n",
    "\n",
    "\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fullBoardArray = np.empty([len(CompleteSet), 768], dtype = np.int8)\n",
    "# fullAnswerArray = np.empty([len(CompleteSet), 64], dtype = np.int8)\n",
    "# fullTurnArray = np.empty([len(CompleteSet), 1], dtype = np.int8)\n",
    "# fullTotalturnArray = np.empty([len(CompleteSet), 1], dtype = np.int8)\n",
    "\n",
    "# for count, row in enumerate(CompleteSet):\n",
    "#     flatRowPre = [item for sublist in row['board'] for item in sublist]\n",
    "#     flatRow = [item for sublist in flatRowPre for item in sublist]\n",
    "#     fullBoardArray[count] = np.array(flatRow)\n",
    "#     fullAnswerArray[count] = np.array(row['answer'])\n",
    "#     fullTurnArray[count] = np.array(row['turn'])\n",
    "#     fullTotalturnArray[count] = np.array(row['totalTurns'])\n",
    "    \n",
    "# print(fullBoardArray[0])\n",
    "# print(fullAnswerArray[0])\n",
    "# print(fullTurnArray[0])\n",
    "# print(fullTotalturnArray[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fullBoardArray = np.empty([len(CompleteSet), 8,8,12], dtype = np.int8)\n",
    "# fullAnswerArray = np.empty([len(CompleteSet), 64], dtype = np.int8)\n",
    "# fullTurnArray = np.empty([len(CompleteSet), 1], dtype = np.int8)\n",
    "# fullTotalturnArray = np.empty([len(CompleteSet), 1], dtype = np.int8)\n",
    "\n",
    "# for count, row in enumerate(CompleteSet):\n",
    "#     #flatRowPre = [item for sublist in row['board'] for item in sublist]\n",
    "#     #flatRow = [item for sublist in flatRowPre for item in sublist]\n",
    "    \n",
    "#     flatRow = row['board']\n",
    "    \n",
    "#     fullBoardArray[count] = np.array(flatRow)\n",
    "#     fullAnswerArray[count] = np.array(row['answer'])\n",
    "#     fullTurnArray[count] = np.array(row['turn'])\n",
    "#     fullTotalturnArray[count] = np.array(row['totalTurns'])\n",
    "    \n",
    "# print(fullBoardArray[0])\n",
    "# print(fullAnswerArray[0])\n",
    "# print(fullTurnArray[0])\n",
    "# print(fullTotalturnArray[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fullBoardArray_TRAIN = fullBoardArray[:77000]\n",
    "# fullBoardArray_TEST = fullBoardArray[77000:]\n",
    "# fullAnswerArray_TRAIN = fullAnswerArray[:77000]\n",
    "# fullAnswerArray_TEST = fullAnswerArray[77000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "pgn = open('Adams.pgn')\n",
    "gameNow = chess.pgn.read_game(pgn)\n",
    "\n",
    "pgn2 = open('Carlsen.pgn')\n",
    "gameNow2 = chess.pgn.read_game(pgn2)\n",
    "\n",
    "piece_color = True\n",
    "if re.search('Adams', gameNow.headers[\"White\"]) != None:\n",
    "            piece_color = False\n",
    "\n",
    "print(piece_color)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headers(Event='Lloyds Bank op', Site='London', Date='1984.??.??', Round='1', White='Adams, Michael', Black='Sedgwick, David', Result='1-0', BlackElo='', ECO='C05', WhiteElo='')\n",
      "Headers(Event='Troll Masters', Site='Gausdal NOR', Date='2001.01.05', Round='1', White='Edvardsen,R', Black='Carlsen,Magnus', Result='1/2-1/2', BlackElo='', ECO='D12', WhiteElo='2055')\n"
     ]
    }
   ],
   "source": [
    "print(gameNow.headers)\n",
    "print(gameNow2.headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
